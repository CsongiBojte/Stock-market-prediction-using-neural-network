{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMGKEe2SVJVHWFOG8OmCkZf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction')\n","\n","from config import *"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NANtRXXjBzMs","executionInfo":{"status":"ok","timestamp":1741081701377,"user_tz":-120,"elapsed":1169,"user":{"displayName":"Bőjte Csongor","userId":"17903094301082678762"}},"outputId":"b6944bcf-eaf3-40bf-b4e4-32ed125fa3d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zDYwkQu59SOW"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","\n","def create_sequences(data, seq_length=21, feature_cols=None, target_col='Target'):\n","    feature_cols = feature_cols if feature_cols else data.columns.drop(target_col).tolist()\n","    num_samples = len(data) - seq_length\n","    num_features = len(feature_cols)\n","\n","    X = np.zeros((num_samples, seq_length, num_features), dtype=np.float32)\n","    y = np.zeros(num_samples, dtype=np.float32)\n","\n","    for i in range(num_samples):\n","        X[i] = data[feature_cols].values[i:(i + seq_length)]\n","        y[i] = data[target_col].values[i + seq_length]\n","\n","    return X, y\n","\n","# def load_and_prepare_data(processed_path,\n","#                           train_file,\n","#                           val_file,\n","#                           test_file,\n","#                           seq_length=21,\n","#                           feature_cols=None,\n","#                           target_col='Target',\n","#                           train_dir='train',\n","#                           val_dir='val',\n","#                           test_dir='test'):\n","\n","#     train = pd.read_csv(os.path.join(processed_path, train_dir, train_file), index_col=0, parse_dates=True)\n","#     val = pd.read_csv(os.path.join(processed_path, val_dir, val_file), index_col=0, parse_dates=True)\n","#     test = pd.read_csv(os.path.join(processed_path, test_dir, test_file), index_col=0, parse_dates=True)\n","\n","#     print(test.shape)\n","#     X_train, y_train = create_sequences(train, seq_length, feature_cols, target_col)\n","#     X_val, y_val = create_sequences(val, seq_length, feature_cols, target_col)\n","#     X_test, y_test = create_sequences(test, seq_length, feature_cols, target_col)\n","\n","#     return (X_train, y_train), (X_val, y_val), (X_test, y_test)"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import joblib\n","\n","def load_and_prepare_data(processed_path, file_prefix, scaler_path):\n","    \"\"\"\n","    Load preprocessed data and scalers from .npy files and joblib.\n","\n","    Args:\n","        processed_path (str): Path to the directory containing preprocessed .npy files.\n","        file_prefix (str): Prefix used for saving the .npy files (e.g., 'custom_split_first').\n","        scaler_path (str): Path to the directory containing the saved scalers.\n","\n","    Returns:\n","        (X_train, y_train), (X_val, y_val), (X_test, y_test), scaler_X, scaler_y\n","    \"\"\"\n","    # Load the scaled data from .npy files\n","    X_train = np.load(os.path.join(processed_path, f\"{file_prefix}_X_train.npy\"))\n","    y_train = np.load(os.path.join(processed_path, f\"{file_prefix}_y_train.npy\"))\n","\n","    X_val = np.load(os.path.join(processed_path, f\"{file_prefix}_X_val.npy\"))\n","    y_val = np.load(os.path.join(processed_path, f\"{file_prefix}_y_val.npy\"))\n","\n","    X_test = np.load(os.path.join(processed_path, f\"{file_prefix}_X_test.npy\"))\n","    y_test = np.load(os.path.join(processed_path, f\"{file_prefix}_y_test.npy\"))\n","\n","    # Load the scalers using joblib\n","    scaler_X = joblib.load(os.path.join(scaler_path, f\"{file_prefix}_scaler_X.joblib\"))\n","    scaler_y = joblib.load(os.path.join(scaler_path, f\"{file_prefix}_scaler_y.joblib\"))\n","\n","    # Return the loaded data and scalers\n","    return (X_train, y_train), (X_val, y_val), (X_test, y_test), (scaler_X, scaler_y)"],"metadata":{"id":"9xEKxPK8L158","executionInfo":{"status":"ok","timestamp":1741293790101,"user_tz":-120,"elapsed":22,"user":{"displayName":"Bőjte Csongor","userId":"17903094301082678762"}}},"execution_count":15,"outputs":[]}]}