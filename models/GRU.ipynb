{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNWq8hqCK18OXIqUqredjwo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f815c08fbb5c4ebaa95cc7fbf2888cc7":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_98a6d45cd83a4edb94f0771350955e4f","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[32m⠏\u001b[0m Waiting for authorization\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠏</span> Waiting for authorization\n</pre>\n"},"metadata":{}}]}},"98a6d45cd83a4edb94f0771350955e4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":37374,"status":"ok","timestamp":1747659515367,"user":{"displayName":"Bőjte Csongor","userId":"17903094301082678762"},"user_tz":-180},"id":"yGCiYK1L-yy1","outputId":"442b6121-b6a4-43b3-df29-013cb887b53a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m700.2/700.2 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install --upgrade mlflow dagshub -q\n","!pip install pyngrok -q\n","!pip install --upgrade keras_tuner -q"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24837,"status":"ok","timestamp":1747659541919,"user":{"displayName":"Bőjte Csongor","userId":"17903094301082678762"},"user_tz":-180},"id":"b_e-DSwB821Z","outputId":"a33692c9-ab68-4bc9-b33c-7cd689994867"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction')\n","\n","import os\n","import joblib\n","import random\n","import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","from tabulate import tabulate\n","\n","from bokeh.plotting import figure, show, output_notebook\n","from bokeh.layouts import column, row\n","from bokeh.palettes import Category10\n","from bokeh.models import ColumnDataSource, HoverTool, Legend\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import (\n","    LSTM,\n","    Dense,\n","    Dropout,\n","    Input,\n","    BatchNormalization,\n","    Bidirectional\n",")\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.optimizers import AdamW\n","from tensorflow.keras.callbacks import (\n","    EarlyStopping,\n","    ModelCheckpoint,\n","    ReduceLROnPlateau\n",")\n","from tensorflow.keras.regularizers import L1L2, l2\n","from tensorflow.keras.metrics import (\n","    MeanAbsolutePercentageError,\n","    RootMeanSquaredError,\n","    MeanAbsoluteError,\n","    MeanSquaredError\n",")\n","\n","from sklearn.metrics import (\n","    mean_squared_error,\n","    mean_absolute_error,\n","    mean_absolute_percentage_error,\n","    mean_squared_error,\n","    root_mean_squared_error\n",")\n","\n","from config import *\n","\n","from mlflow.models.signature import infer_signature\n","from bokeh.plotting import output_file, save\n","\n","import dagshub\n","import mlflow\n","\n","output_notebook()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226,"referenced_widgets":["f815c08fbb5c4ebaa95cc7fbf2888cc7","98a6d45cd83a4edb94f0771350955e4f"]},"executionInfo":{"elapsed":4892,"status":"ok","timestamp":1747659561812,"user":{"displayName":"Bőjte Csongor","userId":"17903094301082678762"},"user_tz":-180},"id":"cS2pccWqdONo","outputId":"be38242d-2d0b-4408-e557-2434547effdb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["                                       \u001b[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001b[0m                                        \n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">❗❗❗ AUTHORIZATION REQUIRED ❗❗❗</span>                                        \n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f815c08fbb5c4ebaa95cc7fbf2888cc7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Open the following link in your browser to authorize the client:\n","https://dagshub.com/login/oauth/authorize?state=b9847575-f661-42e7-ad06-8d003e9bfa5b&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=7dac3c2a270e3f5cd57bd9dd0f31ab2d768e78d7e04bd84e0c46ca5e226e84c2\n","\n","\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Accessing as bojte.csongor\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as bojte.csongor\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Initialized MLflow to track repo \u001b[32m\"bojte.csongor/stock_market_prediction_thesis\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"bojte.csongor/stock_market_prediction_thesis\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Repository bojte.csongor/stock_market_prediction_thesis initialized!\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository bojte.csongor/stock_market_prediction_thesis initialized!\n","</pre>\n"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<Experiment: artifact_location='mlflow-artifacts:/d10aec8d63d244508f6c54660dee98d4', creation_time=1745051301607, experiment_id='2', last_update_time=1745051301607, lifecycle_stage='active', name='GRU', tags={}>"]},"metadata":{},"execution_count":3}],"source":["dagshub.init(repo_owner='bojte.csongor', repo_name='stock_market_prediction_thesis', mlflow=True)\n","\n","mlflow.set_tracking_uri(\"https://dagshub.com/bojte.csongor/stock_market_prediction_thesis.mlflow\")\n","mlflow.set_experiment(experiment_name=\"GRU\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UjhbRywMqTDg"},"outputs":[],"source":["seed=42\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n","np.random.seed(seed)\n","random.seed(seed)\n","tf.random.set_seed(seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CVBng5N4437J"},"outputs":[],"source":["def load_datasets(data_path, dataset_name):\n","    train_data = pd.read_csv(f\"{data_path}/{dataset_name}_train.csv\", index_col=0)\n","    val_data = pd.read_csv(f\"{data_path}/{dataset_name}_val.csv\", index_col=0)\n","    test_data = pd.read_csv(f\"{data_path}/{dataset_name}_test.csv\", index_col=0)\n","\n","    try:\n","        train_data.index = pd.to_datetime(train_data.index, utc=True),\n","        val_data.index = pd.to_datetime(val_data.index, utc=True),\n","        test_data.index = pd.to_datetime(test_data.index, utc=True)\n","    except:\n","        pass\n","\n","    scaler = joblib.load(f\"{data_path}/{dataset_name}_scaler.joblib\")\n","    return train_data, val_data, test_data, scaler"]},{"cell_type":"code","source":["def create_sequences(data, feature_cols, target_cols, sequence_length):\n","    features = data[feature_cols].values\n","    targets = data[target_cols].values\n","\n","    n_samples = len(data) - sequence_length\n","    n_features = len(feature_cols)\n","    n_targets = len(target_cols)\n","\n","    X = np.zeros((n_samples, sequence_length, n_features))\n","    y = np.zeros((n_samples, n_targets))\n","\n","    for i in range(n_samples):\n","        X[i] = features[i:i+sequence_length]\n","        y[i] = targets[i+sequence_length-1]\n","\n","    return X, y"],"metadata":{"id":"n04XV9li4rIa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_all_sequences(train,val,test, feature_cols, target_cols, sequence_length):\n","    X_train, y_train = create_sequences(\n","        data=train,\n","        feature_cols=feature_cols,\n","        target_cols=target_cols,\n","        sequence_length=sequence_length,\n","    )\n","    X_val, y_val = create_sequences(\n","        data=val,\n","        feature_cols=feature_cols,\n","        target_cols=target_cols,\n","        sequence_length=sequence_length,\n","    )\n","    X_test, y_test = create_sequences(\n","        data=test,\n","        feature_cols=feature_cols,\n","        target_cols=target_cols,\n","        sequence_length=sequence_length,\n","    )\n","    return X_train, y_train, X_val, y_val, X_test, y_test"],"metadata":{"id":"a8853EQ5BYuj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_cols_custom = ['Custom_Normalized']\n","target_cols_custom = ['Target']\n","sequence_length = 10\n","\n","train_log_data_custom, val_log_data_custom, test_log_data_custom, custom_log_scaler = load_datasets(\n","    data_path=f\"{PROCESSED_DATA_PATH}/custom_split_first\",\n","    dataset_name=\"log_data\"\n",")\n","\n","X_train_log_custom, y_train_log_custom, X_val_log_custom, y_val_log_custom, X_test_log_custom, y_test_log_custom = create_all_sequences(\n","    train=train_log_data_custom,\n","    val=val_log_data_custom,\n","    test=test_log_data_custom,\n","    feature_cols=feature_cols_custom,\n","    target_cols=target_cols_custom,\n","    sequence_length=sequence_length,\n",")"],"metadata":{"id":"pXdJDJ-oZJXs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"X train shape:\",X_train_log_custom.shape)\n","print(\"y train shape:\", y_train_log_custom.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xs1-aMO9Czer","executionInfo":{"status":"ok","timestamp":1745602859749,"user_tz":-180,"elapsed":11,"user":{"displayName":"Bőjte Csongor","userId":"17903094301082678762"}},"outputId":"2d0f75f7-ce89-48b1-94a7-8c9ee897145a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X train shape: (1925, 10, 1)\n","y train shape: (1925, 1)\n"]}]},{"cell_type":"code","source":["def inverse_transform_simple(df, scaler, log_scaled=False):\n","    df = df.copy()\n","    inverse_scaled = scaler.inverse_transform(df)\n","\n","    if log_scaled:\n","        inverse_scaled = np.exp(inverse_scaled)\n","\n","    return inverse_scaled"],"metadata":{"id":"szs1w-HtRLqV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def inverse_custom_normalize(normalized_value, last_value, index, n):\n","    if index == 0:\n","        return 0\n","    part1 = last_value * (index / n)\n","    sqrt_part = np.sqrt(index**2 + ((last_value * index) / n)**2)\n","    part2 = normalized_value * (sqrt_part / index)\n","    return part1 + part2\n","\n","def add_first_value(data, first_value):\n","    return data + first_value\n","\n","def inverse_transform_custom(arr, scaler, n, first_value, last_value, train_data,val_data,column_name='Custom_Normalized', log_scaled=False):\n","    start_index = len(train_data) + len(val_data)\n","    original_indices = np.arange(start_index, start_index + len(arr))\n","\n","    inverse_minmax = scaler.inverse_transform(arr)[:,0]\n","\n","    df_real = pd.DataFrame(inverse_minmax, columns=[column_name],\n","    index=original_indices)\n","\n","    real_values = []\n","\n","    for i, index in enumerate(df_real.index):\n","        real_value = inverse_custom_normalize(df_real.iloc[i, 0], last_value, index+sequence_length, n)\n","        real_values.append(real_value)\n","\n","    real_values = add_first_value(np.array(real_values), first_value)\n","\n","    if log_scaled:\n","        real_values = np.exp(real_values)\n","\n","    return real_values"],"metadata":{"id":"Ro_JC9VCdmXO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["log_data_path = f\"{PROCESSED_DATA_PATH}/custom_split_first/log_data_custom_scaler.csv\"\n","raw_data_log = pd.read_csv(log_data_path)\n","\n","first_value_log = raw_data_log['first_value'].iloc[0]\n","first_index_log = 0\n","last_value_log = raw_data_log['last_value'].iloc[0]\n","last_index_log = raw_data_log['last_index'].iloc[0]"],"metadata":{"id":"K8MEoVmm3jTI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def log_run_metadata(params: dict, tags: dict):\n","    for k, v in params.items():\n","        mlflow.log_param(k, v)\n","    for k, v in tags.items():\n","        mlflow.set_tag(k, v)"],"metadata":{"id":"d8fCbB_gw9JQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_and_log_metrics(model, NORM_TYPE, X_test, y_test, scaler, model_name, custom, log_scaled, last_index, first_value, last_value, train_data,val_data):\n","    if(NORM_TYPE == 'minmax_split_first_log'): log_scaled = True;\n","    y_pred = model.predict(X_test)\n","\n","    if custom:\n","      y_pred_ext = np.hstack([y_pred, np.zeros_like(y_pred)])\n","      y_pred_real = inverse_transform_custom(y_pred_ext, scaler, last_index, first_value, last_value, train_data,val_data,log_scaled=log_scaled)\n","\n","      y_test_ext = np.hstack([y_test, np.zeros_like(y_test)])\n","      y_test_real = inverse_transform_custom(y_test_ext, scaler, last_index, first_value, last_value, train_data,val_data,log_scaled=log_scaled)\n","    else:\n","      y_pred_ext = np.hstack([y_pred, np.zeros_like(y_pred)])\n","      y_pred_real = inverse_transform_simple(y_pred_ext, scaler,log_scaled=log_scaled)[:, 0].reshape(-1, 1)\n","\n","      y_test_ext = np.hstack([y_test, np.zeros_like(y_test)])\n","      y_test_real = inverse_transform_simple(y_test_ext, scaler,log_scaled=log_scaled)[:, 0].reshape(-1, 1)\n","\n","    metrics = evaluate_predictions(model_name, y_test_real, y_pred_real, should_print=True)\n","\n","    mlflow.log_metric('mape', metrics['mape'])\n","    mlflow.log_metric('mse', metrics['mse'])\n","    mlflow.log_metric('mae', metrics['mae'])\n","    mlflow.log_metric('mpd', metrics['mpd'])\n","    mlflow.log_metric('rmse', metrics['rmse'])\n","\n","    return y_test_real, y_pred_real"],"metadata":{"id":"Fofm1mgTxDna"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_callbacks(model_name, save_path):\n","    checkpoint_path = os.path.join(save_path)\n","\n","    callbacks = [\n","        ModelCheckpoint(\n","            filepath=checkpoint_path,\n","            monitor='val_loss',\n","            mode='min',\n","            save_best_only=True,\n","            save_weights_only=False,\n","            verbose=1\n","        ),\n","        EarlyStopping(\n","            monitor='val_loss',\n","            patience=10,\n","            mode='min',\n","            restore_best_weights=True,\n","            verbose=0\n","        ),\n","        ReduceLROnPlateau(\n","            monitor='val_loss',\n","            factor=0.5,\n","            patience=5,\n","            min_lr=1e-7,\n","            verbose=1,\n","            mode='min'\n","        ),\n","    ]\n","\n","    return callbacks"],"metadata":{"id":"ojLRLGQfpeoc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Iof0UzAklOq"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Input, GRU, Dense, LayerNormalization, Dropout\n","from tensorflow.keras.regularizers import l2\n","\n","def create_gru_model(\n","    input_shape,\n","    units,\n","    activation,\n","    loss,\n","    optimizer,\n","    use_layer_norm = False,\n","    use_regularization = False,\n","    dropout = 0.0\n","):\n","    model = Sequential()\n","    model.add(Input(shape=input_shape))\n","\n","    layers = len(units)\n","\n","    for i in range(layers):\n","        return_seq = i < layers - 1\n","\n","        gru_kwargs = {\n","            \"units\": units[i],\n","            \"activation\": activation,\n","            \"return_sequences\": return_seq\n","        }\n","\n","        if use_regularization:\n","            gru_kwargs.update({\n","                \"recurrent_regularizer\": l2(),\n","                \"activity_regularizer\": l2(),\n","                \"kernel_regularizer\": l2(),\n","            })\n","\n","        model.add(GRU(**gru_kwargs))\n","\n","        if use_layer_norm:\n","            model.add(LayerNormalization())\n","\n","        if dropout > 0.0:\n","            model.add(Dropout(dropout))\n","\n","    model.add(Dense(1))\n","    model.compile(optimizer=optimizer, loss=loss)\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"N_Ru14njA5Wh"},"outputs":[],"source":["from mlflow.models.signature import infer_signature\n","import time\n","from bokeh.plotting import reset_output\n","\n","def run_experiment_group(\n","    model_type: str,\n","    units: list[int],\n","    optimizer_config: dict,\n","    learning_rate: float,\n","    loss: str,\n","    activation: str,\n","    experiment_name,\n","    batch_size: int,\n","    epochs: int,\n","    sequence_length: int,\n","    X_train_data,\n","    y_train_data,\n","    X_val_data,\n","    y_val_data,\n","    X_test_data,\n","    y_test_data,\n","    scaler,\n","    feature_cols,\n","    norm_type: str,\n","    create_model_fn,\n","    use_layer_norm: bool = True,\n","    use_regularization: bool = True,\n","    dropout: float = 0.0,\n","    save_dir: str = CHECKPOINTS_PATH,\n","    custom=False,\n","    log_scaled=False,\n","    train_data=None,\n","    val_data=None,\n","    extra_name: str = \"v1\",\n","    num_runs: int = 1\n","):\n","    # Generate the description from parameters\n","    description = generate_description(\n","        model_type=model_type,\n","        layers=len(units),\n","        units=units,\n","        activation=activation,\n","        norm=use_layer_norm,\n","        reg=use_regularization,\n","        dropout=dropout,\n","        seq_len=sequence_length,\n","        loss=loss,\n","        optimizer_name=optimizer_config[\"name\"],\n","        extra=extra_name\n","    )\n","\n","    for run_index in range(num_runs):\n","        with mlflow.start_run() as run:\n","            run_id = run.info.run_id\n","            model_name = f\"{model_type}_{run_index}_{run_id}\"\n","            checkpoint_path = os.path.join(save_dir, model_type, f\"{model_name}.keras\")\n","\n","            model_dir = os.path.dirname(checkpoint_path)\n","            os.makedirs(model_dir, exist_ok=True)\n","\n","            input_shape = X_train_data.shape[1:]\n","\n","            # --- Logging setup ---\n","            run_group = f\"{model_type}_{description}\"\n","            mlflow.set_tag(\"mlflow.runName\", model_name)\n","            mlflow.set_tag(\"architecture_type\", description)\n","            mlflow.set_tag(\"run_group\", run_group)\n","            mlflow.set_tag(\"run_index\", run_index)\n","            mlflow.set_tag(\"experiment_name\", experiment_name)\n","\n","            log_run_metadata(\n","                params={\n","                    \"normalization_method\": norm_type,\n","                    \"extra_name\": extra_name,\n","                    \"input_shape\": input_shape,\n","                    \"sequence_length\": sequence_length,\n","                    \"features\": feature_cols,\n","                    \"activation\": activation,\n","                    \"optimizer\": optimizer_config['name'],\n","                    \"learning_rate\": learning_rate,\n","                    \"lossfn\": loss,\n","                    \"layers\": len(units),\n","                    \"units\": \"_\".join(map(str, units)),\n","                    \"batch_size\": batch_size,\n","                    \"epochs\": epochs,\n","                    \"use_layer_norm\": use_layer_norm,\n","                    \"use_regularization\": use_regularization,\n","                    \"dropout\": dropout\n","                },\n","                tags={\n","                    \"model\": model_type,\n","                    \"architecture\": \"_\".join(map(str, units)),\n","                    \"description\": description,\n","                    \"sequence_length\": sequence_length\n","                }\n","            )\n","\n","            # --- Model creation & training ---\n","            model = create_model_fn(\n","                input_shape=input_shape,\n","                units=units,\n","                activation=activation,\n","                loss=loss,\n","                optimizer=optimizer_config['create'](),\n","                use_layer_norm=use_layer_norm,\n","                use_regularization=use_regularization,\n","                dropout=dropout\n","            )\n","\n","            callbacks = get_callbacks(model_name, checkpoint_path)\n","\n","            history = model.fit(\n","                X_train_data, y_train_data,\n","                validation_data=(X_val_data, y_val_data),\n","                epochs=epochs,\n","                batch_size=batch_size,\n","                callbacks=callbacks,\n","                shuffle=False,\n","                verbose=0\n","            )\n","\n","            # --- Load best model ---\n","            loaded_model = load_model(checkpoint_path)\n","\n","            # --- Evaluation & logging ---\n","            y_test_real, y_pred_real = evaluate_and_log_metrics(\n","                loaded_model, norm_type, X_test_data, y_test_data,\n","                scaler, model_name, custom=custom, log_scaled=log_scaled,\n","                last_index=last_index_log, first_value=first_value_log, last_value=last_value_log, train_data=train_data, val_data=val_data\n","            )\n","\n","            print(y_test_real[-5:])\n","\n","            # --- Artifact logging ---\n","            artifact_dir = os.path.join(\"artifacts\", model_type, run_id)\n","            os.makedirs(artifact_dir, exist_ok=True)\n","\n","            # Log model\n","            mlflow.keras.log_model(loaded_model, artifact_path=\"best_model\")\n","\n","            # Save model summary\n","            model_summary_path = os.path.join(artifact_dir, \"model_summary.txt\")\n","            with open(model_summary_path, \"w\") as f:\n","                loaded_model.summary(print_fn=lambda x: f.write(x + \"\\n\"))\n","\n","            # Save predictions plot\n","            fig = plot_predictions_bokeh(y_test_real, y_pred_real)\n","            pred_plot_path = os.path.join(artifact_dir, \"predictions_plot.html\")\n","            save(fig, filename=pred_plot_path)\n","\n","            # Save training plot\n","            training_plot = plot_training_history(history)\n","            history_plot_path = os.path.join(artifact_dir, \"training_history_plot.html\")\n","            save(training_plot, filename=history_plot_path)\n","\n","            # 🚀 Log all artifacts at once\n","            mlflow.log_artifacts(artifact_dir)\n","\n","            print(f\"[✓] Run {run_index + 1}/{num_runs} complete — {model_name}\")"]},{"cell_type":"markdown","source":["architecture - with_drop -\n","hyperparameter - optimizer - activation_fn - batch_size\n","silu\n","0,002\n","1layer, 16 neuron\n","loss scale - lamb\n","128 batch\n","regularizations\n"],"metadata":{"id":"4cwWYcfBwH_6"}},{"cell_type":"code","source":["from keras.optimizers import Lamb, Lion,Adamax, LossScaleOptimizer\n","\n","learning_rate = 0.002\n","run_experiment_group(\n","    model_type=\"GRU\",\n","    num_runs=5,\n","    extra_name=\"\",\n","    experiment_name=\"final_verison\",\n","    units=[16],\n","    batch_size=128,\n","    epochs=500,\n","    optimizer_config={\n","        \"name\": \"LosScaleOptimizer-Lamb\",\n","        \"create\": lambda: LossScaleOptimizer(Lamb(learning_rate))\n","    },\n","    learning_rate=learning_rate,\n","    loss=\"mse\",\n","    activation=\"silu\",\n","    use_layer_norm=False,\n","    use_regularization=True,\n","    dropout=0,\n","    sequence_length=sequence_length,\n","    feature_cols=feature_cols_custom,\n","    norm_type='custom_log_split_first',\n","    custom=True,\n","    log_scaled=True,\n","    scaler=custom_log_scaler,\n","    create_model_fn=create_gru_model,\n","    X_train_data=X_train_log_custom,\n","    y_train_data=y_train_log_custom,\n","    X_val_data=X_val_log_custom,\n","    y_val_data=y_val_log_custom,\n","    X_test_data=X_test_log_custom,\n","    y_test_data=y_test_log_custom,\n","    train_data=train_log_data_custom,\n","    val_data=val_log_data_custom,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"b7-VvGZjx2a7","executionInfo":{"status":"error","timestamp":1745246190399,"user_tz":-180,"elapsed":206783,"user":{"displayName":"Bőjte Csongor","userId":"17903094301082678762"}},"outputId":"47904a8a-6110-4162-807a-04947edabe97","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /bojte.csongor/stock_market_prediction_thesis.mlflow/api/2.0/mlflow/runs/create\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1: val_loss improved from inf to 0.68522, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 2: val_loss improved from 0.68522 to 0.64770, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 3: val_loss improved from 0.64770 to 0.61242, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 4: val_loss improved from 0.61242 to 0.57943, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 5: val_loss improved from 0.57943 to 0.54878, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 6: val_loss improved from 0.54878 to 0.52018, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 7: val_loss improved from 0.52018 to 0.49331, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 8: val_loss improved from 0.49331 to 0.46799, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 9: val_loss improved from 0.46799 to 0.44408, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 10: val_loss improved from 0.44408 to 0.42150, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 11: val_loss improved from 0.42150 to 0.40015, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 12: val_loss improved from 0.40015 to 0.37998, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 13: val_loss improved from 0.37998 to 0.36092, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 14: val_loss improved from 0.36092 to 0.34289, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 15: val_loss improved from 0.34289 to 0.32584, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 16: val_loss improved from 0.32584 to 0.30969, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 17: val_loss improved from 0.30969 to 0.29439, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 18: val_loss improved from 0.29439 to 0.27988, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 19: val_loss improved from 0.27988 to 0.26609, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 20: val_loss improved from 0.26609 to 0.25297, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 21: val_loss improved from 0.25297 to 0.24048, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 22: val_loss improved from 0.24048 to 0.22858, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 23: val_loss improved from 0.22858 to 0.21724, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 24: val_loss improved from 0.21724 to 0.20641, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 25: val_loss improved from 0.20641 to 0.19608, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 26: val_loss improved from 0.19608 to 0.18623, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 27: val_loss improved from 0.18623 to 0.17683, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 28: val_loss improved from 0.17683 to 0.16786, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 29: val_loss improved from 0.16786 to 0.15930, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 30: val_loss improved from 0.15930 to 0.15114, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 31: val_loss improved from 0.15114 to 0.14336, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 32: val_loss improved from 0.14336 to 0.13595, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 33: val_loss improved from 0.13595 to 0.12888, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 34: val_loss improved from 0.12888 to 0.12215, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 35: val_loss improved from 0.12215 to 0.11575, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 36: val_loss improved from 0.11575 to 0.10965, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 37: val_loss improved from 0.10965 to 0.10384, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 38: val_loss improved from 0.10384 to 0.09832, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 39: val_loss improved from 0.09832 to 0.09307, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 40: val_loss improved from 0.09307 to 0.08807, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 41: val_loss improved from 0.08807 to 0.08332, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 42: val_loss improved from 0.08332 to 0.07881, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 43: val_loss improved from 0.07881 to 0.07452, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 44: val_loss improved from 0.07452 to 0.07045, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 45: val_loss improved from 0.07045 to 0.06658, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 46: val_loss improved from 0.06658 to 0.06291, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 47: val_loss improved from 0.06291 to 0.05943, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 48: val_loss improved from 0.05943 to 0.05612, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 49: val_loss improved from 0.05612 to 0.05298, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 50: val_loss improved from 0.05298 to 0.05001, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 51: val_loss improved from 0.05001 to 0.04719, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 52: val_loss improved from 0.04719 to 0.04452, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 53: val_loss improved from 0.04452 to 0.04198, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 54: val_loss improved from 0.04198 to 0.03959, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 55: val_loss improved from 0.03959 to 0.03732, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 56: val_loss improved from 0.03732 to 0.03517, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 57: val_loss improved from 0.03517 to 0.03314, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 58: val_loss improved from 0.03314 to 0.03122, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 59: val_loss improved from 0.03122 to 0.02941, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 60: val_loss improved from 0.02941 to 0.02770, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 61: val_loss improved from 0.02770 to 0.02608, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 62: val_loss improved from 0.02608 to 0.02456, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 63: val_loss improved from 0.02456 to 0.02313, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 64: val_loss improved from 0.02313 to 0.02178, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 65: val_loss improved from 0.02178 to 0.02051, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 66: val_loss improved from 0.02051 to 0.01932, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 67: val_loss improved from 0.01932 to 0.01821, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 68: val_loss improved from 0.01821 to 0.01716, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 69: val_loss improved from 0.01716 to 0.01618, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 70: val_loss improved from 0.01618 to 0.01526, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 71: val_loss improved from 0.01526 to 0.01439, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 72: val_loss improved from 0.01439 to 0.01359, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 73: val_loss improved from 0.01359 to 0.01283, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 74: val_loss improved from 0.01283 to 0.01212, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 75: val_loss improved from 0.01212 to 0.01146, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 76: val_loss improved from 0.01146 to 0.01084, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 77: val_loss improved from 0.01084 to 0.01025, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 78: val_loss improved from 0.01025 to 0.00971, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 79: val_loss improved from 0.00971 to 0.00920, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 80: val_loss improved from 0.00920 to 0.00873, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 81: val_loss improved from 0.00873 to 0.00829, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 82: val_loss improved from 0.00829 to 0.00788, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 83: val_loss improved from 0.00788 to 0.00750, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 84: val_loss improved from 0.00750 to 0.00715, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 85: val_loss improved from 0.00715 to 0.00683, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 86: val_loss improved from 0.00683 to 0.00653, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 87: val_loss improved from 0.00653 to 0.00627, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 88: val_loss improved from 0.00627 to 0.00603, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 89: val_loss improved from 0.00603 to 0.00580, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 90: val_loss improved from 0.00580 to 0.00557, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 91: val_loss improved from 0.00557 to 0.00536, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 92: val_loss improved from 0.00536 to 0.00516, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 93: val_loss improved from 0.00516 to 0.00497, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 94: val_loss improved from 0.00497 to 0.00480, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 95: val_loss improved from 0.00480 to 0.00463, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 96: val_loss improved from 0.00463 to 0.00446, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 97: val_loss improved from 0.00446 to 0.00429, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 98: val_loss improved from 0.00429 to 0.00414, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 99: val_loss improved from 0.00414 to 0.00397, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 100: val_loss improved from 0.00397 to 0.00381, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 101: val_loss improved from 0.00381 to 0.00366, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 102: val_loss improved from 0.00366 to 0.00350, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 103: val_loss improved from 0.00350 to 0.00336, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 104: val_loss improved from 0.00336 to 0.00320, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 105: val_loss improved from 0.00320 to 0.00307, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 106: val_loss improved from 0.00307 to 0.00293, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 107: val_loss improved from 0.00293 to 0.00280, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 108: val_loss improved from 0.00280 to 0.00267, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 109: val_loss improved from 0.00267 to 0.00255, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 110: val_loss improved from 0.00255 to 0.00245, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 111: val_loss improved from 0.00245 to 0.00235, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 112: val_loss improved from 0.00235 to 0.00226, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 113: val_loss improved from 0.00226 to 0.00217, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 114: val_loss improved from 0.00217 to 0.00208, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 115: val_loss improved from 0.00208 to 0.00201, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 116: val_loss improved from 0.00201 to 0.00199, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 117: val_loss did not improve from 0.00199\n","\n","Epoch 118: val_loss improved from 0.00199 to 0.00190, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 119: val_loss improved from 0.00190 to 0.00181, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 120: val_loss improved from 0.00181 to 0.00177, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 121: val_loss improved from 0.00177 to 0.00170, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 122: val_loss did not improve from 0.00170\n","\n","Epoch 123: val_loss did not improve from 0.00170\n","\n","Epoch 124: val_loss improved from 0.00170 to 0.00169, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 125: val_loss improved from 0.00169 to 0.00159, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 126: val_loss improved from 0.00159 to 0.00158, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 127: val_loss improved from 0.00158 to 0.00156, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 128: val_loss did not improve from 0.00156\n","\n","Epoch 129: val_loss did not improve from 0.00156\n","\n","Epoch 130: val_loss did not improve from 0.00156\n","\n","Epoch 130: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n","\n","Epoch 131: val_loss did not improve from 0.00156\n","\n","Epoch 132: val_loss improved from 0.00156 to 0.00149, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 133: val_loss improved from 0.00149 to 0.00144, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 134: val_loss improved from 0.00144 to 0.00137, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 135: val_loss improved from 0.00137 to 0.00134, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 136: val_loss did not improve from 0.00134\n","\n","Epoch 137: val_loss did not improve from 0.00134\n","\n","Epoch 138: val_loss improved from 0.00134 to 0.00134, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 139: val_loss improved from 0.00134 to 0.00130, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 139: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\n","Epoch 140: val_loss did not improve from 0.00130\n","\n","Epoch 141: val_loss improved from 0.00130 to 0.00129, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 142: val_loss improved from 0.00129 to 0.00129, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 143: val_loss improved from 0.00129 to 0.00128, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 144: val_loss improved from 0.00128 to 0.00127, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 144: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\n","Epoch 145: val_loss improved from 0.00127 to 0.00127, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 146: val_loss improved from 0.00127 to 0.00126, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 147: val_loss improved from 0.00126 to 0.00125, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 148: val_loss improved from 0.00125 to 0.00125, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 149: val_loss improved from 0.00125 to 0.00125, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 150: val_loss improved from 0.00125 to 0.00124, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 150: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","\n","Epoch 151: val_loss improved from 0.00124 to 0.00124, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 152: val_loss improved from 0.00124 to 0.00124, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 153: val_loss improved from 0.00124 to 0.00124, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 154: val_loss improved from 0.00124 to 0.00124, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 155: val_loss improved from 0.00124 to 0.00124, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 155: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","\n","Epoch 156: val_loss did not improve from 0.00124\n","\n","Epoch 157: val_loss improved from 0.00124 to 0.00124, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 158: val_loss improved from 0.00124 to 0.00124, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 159: val_loss improved from 0.00124 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 160: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 160: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","\n","Epoch 161: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 162: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 163: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 164: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 165: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 165: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","\n","Epoch 166: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 167: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 168: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 169: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 170: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 170: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n","\n","Epoch 171: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 172: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 173: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 174: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 175: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 175: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n","\n","Epoch 176: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 177: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 178: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 179: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 180: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 180: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n","\n","Epoch 181: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 182: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 183: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 184: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 185: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 185: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n","\n","Epoch 186: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 187: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 188: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 189: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 190: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 190: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n","\n","Epoch 191: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 192: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 193: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 194: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 195: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 195: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n","\n","Epoch 196: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 197: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 198: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 199: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 200: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 200: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n","\n","Epoch 201: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 202: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 203: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 204: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 205: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 205: ReduceLROnPlateau reducing learning rate to 1e-07.\n","\n","Epoch 206: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 207: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 208: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 209: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 210: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 211: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 212: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 213: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 214: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 215: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 216: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 217: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 218: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 219: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 220: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 221: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 222: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 223: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 224: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 225: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 226: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 227: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 228: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 229: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 230: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 231: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 232: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 233: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 234: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 235: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 236: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 237: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 238: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 239: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 240: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 241: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 242: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 243: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 244: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 245: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 246: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 247: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 248: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 249: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 250: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 251: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 252: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 253: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 254: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 255: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 256: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 257: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 258: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 259: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 260: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 261: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 262: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 263: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 264: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 265: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 266: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 267: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 268: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 269: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 270: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 271: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 272: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 273: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 274: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 275: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 276: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 277: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 278: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 279: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 280: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 281: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 282: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 283: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 284: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 285: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 286: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 287: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 288: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 289: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 290: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 291: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 292: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 293: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 294: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 295: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 296: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 297: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 298: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 299: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 300: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 301: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 302: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 303: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 304: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 305: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 306: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 307: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 308: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 309: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 310: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 311: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 312: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 313: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 314: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 315: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 316: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 317: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 318: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 319: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 320: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 321: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 322: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 323: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 324: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 325: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 326: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 327: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 328: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 329: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 330: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 331: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 332: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 333: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 334: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 335: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 336: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 337: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 338: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 339: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 340: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 341: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 342: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 343: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 344: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 345: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 346: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 347: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 348: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 349: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 350: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 351: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 352: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 353: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 354: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 355: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 356: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 357: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 358: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 359: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 360: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 361: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 362: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 363: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 364: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 365: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 366: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 367: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 368: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 369: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 370: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 371: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 372: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 373: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 374: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 375: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 376: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 377: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 378: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 379: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 380: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 381: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 382: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 383: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 384: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 385: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 386: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 387: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 388: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 389: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 390: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 391: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 392: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 393: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 394: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 395: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 396: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 397: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 398: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 399: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 400: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 401: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 402: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 403: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 404: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 405: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 406: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 407: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 408: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 409: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 410: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 411: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 412: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 413: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 414: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 415: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 416: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 417: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 418: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 419: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 420: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 421: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 422: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 423: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 424: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 425: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 426: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 427: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 428: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 429: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 430: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 431: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 432: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 433: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 434: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 435: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 436: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 437: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 438: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 439: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 440: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 441: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 442: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 443: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 444: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 445: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 446: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 447: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 448: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 449: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 450: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 451: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 452: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 453: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 454: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 455: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 456: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 457: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 458: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 459: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 460: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 461: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 462: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 463: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 464: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 465: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 466: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 467: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 468: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 469: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 470: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 471: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 472: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 473: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 474: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 475: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 476: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 477: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 478: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 479: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 480: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 481: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 482: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 483: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 484: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 485: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 486: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 487: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 488: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 489: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 490: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 491: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 492: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 493: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 494: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 495: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 496: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 497: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 498: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 499: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\n","Epoch 500: val_loss improved from 0.00123 to 0.00123, saving model to /content/drive/MyDrive/Colab Notebooks/Stock_Market_Prediction/checkpoints/GRU/GRU_0_10ab968352434ed8987c023d1a5ba9ae.keras\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n","\n","Model Performance Metrics:\n","--------------------------------------------------\n","MAPE: 0.6607%\n","RMSE: 43.18498560\n","MSE: 1864.94298108\n","MAE: 33.07525955\n","MPD (Maximum Percentage Deviation): 4.0411%\n","\n","Point of Maximum Deviation (Index 304):\n","--------------------------------------------------\n","True Value: 5186.330078\n","Predicted Value: 5395.914673\n","Absolute Difference: 209.584595\n","Percentage Deviation: 4.04%\n"]},{"output_type":"stream","name":"stderr","text":["2025/04/21 14:36:05 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"]},{"output_type":"stream","name":"stdout","text":["[5867.08007812 5930.85009766 5974.06982422 6040.04003906 6037.58984375]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[31m2025/04/21 14:36:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["'use strict';\n","(function(root) {\n","  function now() {\n","    return new Date();\n","  }\n","\n","  const force = true;\n","\n","  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n","    root._bokeh_onload_callbacks = [];\n","    root._bokeh_is_loading = undefined;\n","  }\n","\n","const JS_MIME_TYPE = 'application/javascript';\n","  const HTML_MIME_TYPE = 'text/html';\n","  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n","  const CLASS_NAME = 'output_bokeh rendered_html';\n","\n","  /**\n","   * Render data to the DOM node\n","   */\n","  function render(props, node) {\n","    const script = document.createElement(\"script\");\n","    node.appendChild(script);\n","  }\n","\n","  /**\n","   * Handle when an output is cleared or removed\n","   */\n","  function handleClearOutput(event, handle) {\n","    function drop(id) {\n","      const view = Bokeh.index.get_by_id(id)\n","      if (view != null) {\n","        view.model.document.clear()\n","        Bokeh.index.delete(view)\n","      }\n","    }\n","\n","    const cell = handle.cell;\n","\n","    const id = cell.output_area._bokeh_element_id;\n","    const server_id = cell.output_area._bokeh_server_id;\n","\n","    // Clean up Bokeh references\n","    if (id != null) {\n","      drop(id)\n","    }\n","\n","    if (server_id !== undefined) {\n","      // Clean up Bokeh references\n","      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n","      cell.notebook.kernel.execute(cmd_clean, {\n","        iopub: {\n","          output: function(msg) {\n","            const id = msg.content.text.trim()\n","            drop(id)\n","          }\n","        }\n","      });\n","      // Destroy server and session\n","      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n","      cell.notebook.kernel.execute(cmd_destroy);\n","    }\n","  }\n","\n","  /**\n","   * Handle when a new output is added\n","   */\n","  function handleAddOutput(event, handle) {\n","    const output_area = handle.output_area;\n","    const output = handle.output;\n","\n","    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n","    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n","      return\n","    }\n","\n","    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n","\n","    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n","      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n","      // store reference to embed id on output_area\n","      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n","    }\n","    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n","      const bk_div = document.createElement(\"div\");\n","      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n","      const script_attrs = bk_div.children[0].attributes;\n","      for (let i = 0; i < script_attrs.length; i++) {\n","        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n","        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n","      }\n","      // store reference to server id on output_area\n","      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n","    }\n","  }\n","\n","  function register_renderer(events, OutputArea) {\n","\n","    function append_mime(data, metadata, element) {\n","      // create a DOM node to render to\n","      const toinsert = this.create_output_subarea(\n","        metadata,\n","        CLASS_NAME,\n","        EXEC_MIME_TYPE\n","      );\n","      this.keyboard_manager.register_events(toinsert);\n","      // Render to node\n","      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n","      render(props, toinsert[toinsert.length - 1]);\n","      element.append(toinsert);\n","      return toinsert\n","    }\n","\n","    /* Handle when an output is cleared or removed */\n","    events.on('clear_output.CodeCell', handleClearOutput);\n","    events.on('delete.Cell', handleClearOutput);\n","\n","    /* Handle when a new output is added */\n","    events.on('output_added.OutputArea', handleAddOutput);\n","\n","    /**\n","     * Register the mime type and append_mime function with output_area\n","     */\n","    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n","      /* Is output safe? */\n","      safe: true,\n","      /* Index of renderer in `output_area.display_order` */\n","      index: 0\n","    });\n","  }\n","\n","  // register the mime type if in Jupyter Notebook environment and previously unregistered\n","  if (root.Jupyter !== undefined) {\n","    const events = require('base/js/events');\n","    const OutputArea = require('notebook/js/outputarea').OutputArea;\n","\n","    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n","      register_renderer(events, OutputArea);\n","    }\n","  }\n","  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n","    root._bokeh_timeout = Date.now() + 5000;\n","    root._bokeh_failed_load = false;\n","  }\n","\n","  const NB_LOAD_WARNING = {'data': {'text/html':\n","     \"<div style='background-color: #fdd'>\\n\"+\n","     \"<p>\\n\"+\n","     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n","     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n","     \"</p>\\n\"+\n","     \"<ul>\\n\"+\n","     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n","     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n","     \"</ul>\\n\"+\n","     \"<code>\\n\"+\n","     \"from bokeh.resources import INLINE\\n\"+\n","     \"output_notebook(resources=INLINE)\\n\"+\n","     \"</code>\\n\"+\n","     \"</div>\"}};\n","\n","  function display_loaded(error = null) {\n","    const el = document.getElementById(null);\n","    if (el != null) {\n","      const html = (() => {\n","        if (typeof root.Bokeh === \"undefined\") {\n","          if (error == null) {\n","            return \"BokehJS is loading ...\";\n","          } else {\n","            return \"BokehJS failed to load.\";\n","          }\n","        } else {\n","          const prefix = `BokehJS ${root.Bokeh.version}`;\n","          if (error == null) {\n","            return `${prefix} successfully loaded.`;\n","          } else {\n","            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n","          }\n","        }\n","      })();\n","      el.innerHTML = html;\n","\n","      if (error != null) {\n","        const wrapper = document.createElement(\"div\");\n","        wrapper.style.overflow = \"auto\";\n","        wrapper.style.height = \"5em\";\n","        wrapper.style.resize = \"vertical\";\n","        const content = document.createElement(\"div\");\n","        content.style.fontFamily = \"monospace\";\n","        content.style.whiteSpace = \"pre-wrap\";\n","        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n","        content.textContent = error.stack ?? error.toString();\n","        wrapper.append(content);\n","        el.append(wrapper);\n","      }\n","    } else if (Date.now() < root._bokeh_timeout) {\n","      setTimeout(() => display_loaded(error), 100);\n","    }\n","  }\n","\n","  function run_callbacks() {\n","    try {\n","      root._bokeh_onload_callbacks.forEach(function(callback) {\n","        if (callback != null)\n","          callback();\n","      });\n","    } finally {\n","      delete root._bokeh_onload_callbacks\n","    }\n","    console.debug(\"Bokeh: all callbacks have finished\");\n","  }\n","\n","  function load_libs(css_urls, js_urls, callback) {\n","    if (css_urls == null) css_urls = [];\n","    if (js_urls == null) js_urls = [];\n","\n","    root._bokeh_onload_callbacks.push(callback);\n","    if (root._bokeh_is_loading > 0) {\n","      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n","      return null;\n","    }\n","    if (js_urls == null || js_urls.length === 0) {\n","      run_callbacks();\n","      return null;\n","    }\n","    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n","    root._bokeh_is_loading = css_urls.length + js_urls.length;\n","\n","    function on_load() {\n","      root._bokeh_is_loading--;\n","      if (root._bokeh_is_loading === 0) {\n","        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n","        run_callbacks()\n","      }\n","    }\n","\n","    function on_error(url) {\n","      console.error(\"failed to load \" + url);\n","    }\n","\n","    for (let i = 0; i < css_urls.length; i++) {\n","      const url = css_urls[i];\n","      const element = document.createElement(\"link\");\n","      element.onload = on_load;\n","      element.onerror = on_error.bind(null, url);\n","      element.rel = \"stylesheet\";\n","      element.type = \"text/css\";\n","      element.href = url;\n","      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n","      document.body.appendChild(element);\n","    }\n","\n","    for (let i = 0; i < js_urls.length; i++) {\n","      const url = js_urls[i];\n","      const element = document.createElement('script');\n","      element.onload = on_load;\n","      element.onerror = on_error.bind(null, url);\n","      element.async = false;\n","      element.src = url;\n","      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n","      document.head.appendChild(element);\n","    }\n","  };\n","\n","  function inject_raw_css(css) {\n","    const element = document.createElement(\"style\");\n","    element.appendChild(document.createTextNode(css));\n","    document.body.appendChild(element);\n","  }\n","\n","  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.6.3.min.js\"];\n","  const css_urls = [];\n","\n","  const inline_js = [    function(Bokeh) {\n","      Bokeh.set_log_level(\"info\");\n","    },\n","function(Bokeh) {\n","    }\n","  ];\n","\n","  function run_inline_js() {\n","    if (root.Bokeh !== undefined || force === true) {\n","      try {\n","            for (let i = 0; i < inline_js.length; i++) {\n","      inline_js[i].call(root, root.Bokeh);\n","    }\n","\n","      } catch (error) {throw error;\n","      }} else if (Date.now() < root._bokeh_timeout) {\n","      setTimeout(run_inline_js, 100);\n","    } else if (!root._bokeh_failed_load) {\n","      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n","      root._bokeh_failed_load = true;\n","    } else if (force !== true) {\n","      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n","      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n","    }\n","  }\n","\n","  if (root._bokeh_is_loading === 0) {\n","    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n","    run_inline_js();\n","  } else {\n","    load_libs(css_urls, js_urls, function() {\n","      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n","      run_inline_js();\n","    });\n","  }\n","}(window));"],"application/vnd.bokehjs_load.v0+json":"'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(null);\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.6.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {throw error;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","  <div id=\"fb89f40e-ebde-4251-b6fb-cd323e5093cd\" data-root-id=\"p1569\" style=\"display: contents;\"></div>\n"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["(function(root) {\n","  function embed_document(root) {\n","  const docs_json = {\"2289ab4c-e224-4869-b026-23790794533f\":{\"version\":\"3.6.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"p1569\",\"attributes\":{\"children\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1512\",\"attributes\":{\"width\":800,\"height\":400,\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1513\"},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1514\"},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1522\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1523\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1515\",\"attributes\":{\"text\":\"Actual vs Predicted Values\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1554\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1509\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1510\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1511\"},\"data\":{\"type\":\"map\",\"entries\":[[\"index\",[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404]],[\"actual\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[405],\"dtype\":\"float64\",\"order\":\"little\"}],[\"predicted\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"hBqXP7MvsECjEsh/vVGwQPz/yeUOW7BAazYyTghfsEAvLNniHkOwQEMqTGh0JbBAIsn00aQwsEDlA0/knlawQJ6bVEJJZbBAIEGKyt9asEBnv5vbjHCwQJ+WzIX0nrBAB/0SlIWrsEBga2mRmrawQLkOVgatsLBATHP4o9e+sEAbJuOpVcewQOWDQA5547BAaoSppvMAsUAitZP6gw6xQCioL224NLFAYmARc1k5sUDO/IN5Ii6xQAuKkrV/G7FA4JY6FHQesUAwE8z0qAqxQCc7u5/r9rBA8aRm1jIOsUAUNkySKhaxQCnGqsFgJbFA8tQF66FMsUAn/V/7+16xQHUuBreWYLFADSQ+dUVLsUDsg96LQDuxQHqNIgW0O7FAKnX6xFJOsUAy8KtR22mxQAK4YyPki7FAkZpYBCGWsUA29W7t0qSxQO3Afk9kvrFApDKYm97OsUBixt1EDcKxQOFTDYYQvrFA9Reb4uDHsUCPQ+S2k9OxQCAI7HOe17FAQaUSjPDGsUD99hMVV9yxQFQurVW46LFAA5bn8eHlsUBZAKa0Xr2xQNs/pRHIprFAsUf0ykiPsUAmOA9iZZ+xQIuJzLK5mbFAtP+vb9SDsUDhgX4EKXyxQCt1FGA8drFACC0fNeeDsUAJcxHv1WixQDIGegWTSbFAjDOAWWoosUDdyPlCWxuxQJoD+twOKbFAwz7+V7AmsUB61JSL40OxQB1NFizkKbFANwH6lUkysUCA079UpkaxQNmSvbtTdrFAa6SSqWaTsUAil/rWHJqxQOQ28mi5obFAqA1vLduYsUAAwrOD64GxQEGnZx02cLFA7VtHvWNtsUCwC817636xQAYgPre6dbFAFOSPAKd1sUBmvccKAY2xQH3RSTPXc7FAvlYw9DtssUCW0yQSV2OxQOSq0AHaRbFAmSr1IVcNsUC/rChmo/GwQHLxZD3n8bBAlhH3KfLJsEAdfpxGVbuwQERyW3F1xbBA2EDROAvCsEAxWgPU7sCwQO4254OIm7BApfsYhb6isEAzXX3cAqKwQDwZ0UIXwbBAhtDV5fPdsEAMfiT/HPewQO4Ez/FuDLFAf2ukTo0DsUCQt55rfvKwQALbRqmPCLFAq4rDVsIQsUAYQo8eNu+wQPP92ul0y7BARTjp8fmbsEACRrfnbYWwQBoCj5L4j7BA6504gMJtsEDf5eI6hUGwQG7zZokrJLBAp1ZOd/E3sEChmsyRYVCwQLaj89tDdbBALqYwXy61sEAOrnNeH+ewQKts56wp/7BASlekYSIQsUAO0nf7ZBmxQMPU7qbIBrFAyaiMy/opsUDCNuY3NzWxQBZ6ueHGbbFALkQqURSIsUD0ce9uhpWxQHb5a1BHnrFANGjJJl62sUDYfC675rmxQIV49ua2xrFAKTZx5lDNsUBIMAejScqxQJFeU2bly7FAUtknBtDJsUCvLWPtt9OxQD2bKKot6LFA6O7Boo/gsUCN4PTqBNyxQE7Scdolz7FAMhG1a8TgsUA6jTsFMPOxQF4WLzl6BbJA1cLE0bEZskD6n8CutUiyQE4wesSNYrJAIEzhr0RsskCrKMRNP32yQMPh6GD9lLJA0eWDFZByskCM8sQ9foOyQLhwQZTdjrJAWNTm8rCfskBkOA7eYKqyQHuGttiRr7JArKGSrCmpskC0SuZm65WyQKV3EYrhdrJATyIh0ftgskCt5ZuF712yQK9AbZLVhbJAD8aMBdSQskCM20xUv6WyQMjeuRzKq7JAtmm5rVSwskC+G+XM+qayQCwLKGS+krJA038WiuikskCZ1GlCSNCyQC+Q2qeP57JAhffDwUb5skAZolWzhgKzQKPqkSDsFbNAZanU/2Qbs0AcYtkkWTSzQHY6bksbPLNAkkrUucgNs0Csx7F1riGzQLJgfqKsSbNA6TvRvk1Ps0CmLeHAh1izQAs9VHBJdbNAIOd2dxqCs0AMWf+fvpizQGz3Ahd/nrNAVbqBqRt2s0DozOWMGoSzQI22DnRvm7NAZhtpznOVs0A/kgSWiICzQM01ZS9wfLNAEUDIirG7s0CBT8coN9WzQNSYDTEh07NABMIDP6/Xs0C1lA6iOtSzQAR2Aj9G47NApFVC8jECtEDaNd89Twq0QFXgDEUQ7bNA1I65hA3ys0DH5/BIXhS0QGfVQg7JDLRAxWOfPVYGtEB25QtmNCe0QBxoEb+0LbRAFIKlbwsntEAT+4Hd1g+0QCJI9eHyGrRAXqyZZiMxtEAn+qm4CFa0QCfrXeGjbrRAjEb1+ZNztECcMWQhnWu0QLY1VQeMX7RAFUDBcpt2tED1hxLWEoO0QI1Pc7ZWgbRA1dfeYDlptEBs2ogUh2O0QBIWwWeKObRASdIs89JMtECpj9sHBFO0QI56o5YHWrRAtIt+8T4+tEBKXZguX0u0QOhi7lmNIbRAEKjLZFrrs0D3LfC/RdCzQLEq2vzJs7NAMsKgWgais0BRxAuX73+zQJrLlkbSjbNAgRFOcyq4s0BIDtgeJMmzQD8DontIwbNAydXkgSXes0BMEyVKQfOzQIQIi6RsybNA+rSH3b6us0AZZE7p7cCzQLh7BjIk77NANbuf9o4htEBh0c43Szm0QApvF8hnQrRAW3sy9TRWtECq7x9fHmO0QJPBjxtMZ7RA45xIzH14tEA6UFyy66S0QOwY9CM7r7RAzUSnUP+2tEDp5+TA+by0QN46sCt1x7RA7SLpjJjCtEAkAQLvhKi0QG5+KGdUtbRAgOy0gw27tECmxsi3FaW0QEJVT6Q1ibRAWjh65IaYtEDK+NbYB6K0QIJU5diSqrRADqQKSW/UtEDgScYZ5uO0QJg0jQYq5rRAF269mYvvtEDHHrwfGfy0QGzObGcIHbVAs8FWjoUxtUCm7/yCFDi1QKyKB1kyVLVAWumjYH1ntUDUG3s6YGa1QHUdmoOxYLVAKjr8NDNUtUBLFGsVn1y1QIdiKZQkZbVAN7h5aXhrtUAY3UbbGmC1QCZ3yETDZLVAXY2kEWd7tUDhY6DfTZW1QN0PfxLIsbVAPRJqFzfAtUDYqZbnTci1QJoibXlS7rVA/XrFs57etUBYjnc2kOu1QEiUluBG+rVA76NenfwVtkA4bVeCE/C1QKq220WvxrVAaTAemHaetUCypn/EsLO1QC+2ZYWAtrVAP5ZNk/9ntUDYX6jo7zi1QDk+qjLxS7VACo9QgvVVtUCIeDawE0m1QJSpUg/0eLVAGR8/SMRctUBM4wQo6hO1QA/apK00lLRA1EaywniFtEC2PUvhpWa0QEyrrDzSpLRASM2j4x3MtEDV3GgKZNu0QI+UBYqpGLVAO6GvOBg9tUAYCTzeIoG1QKEWl4w1orVASV0UThfQtUAlff5e8Nq1QF2aNwS07bVAi6tEMvrVtUCEq0cNQfS1QLcOn/j39LVA3ZZQcsL6tUD/FZvCRei1QMG63WUT4bVAwq69zgABtkB5ayYtgcO1QKSEIhCpprVAu4xZ9VmRtUDCwNo2T061QLBkNzWMW7VAxVcd3bBvtUAmJYmBdpu1QOxoukHkxbVAHhTDHtLotUCflTf+nPq1QBXgQU9hArZAtahUcVH7tUBy37bZJDO2QAf+83LfQbZA1v32V2BRtkBH3SquJ2C2QChkgMdGX7ZA7ZVXOyVttkBinhZuDG62QHCUnghVfbZA+n5cSiJitkBPkeHiP1i2QP2O7kuOTrZAYRbb/kBqtkADF3MC+FK2QB0oIG0AbLZABFJm4LOOtkC6PehzspS2QI34hFx4rLZAzeDSig/RtkBwpfGgxsO2QMEcoQhrz7ZA1nw3dUfTtkD27Yfp/uK2QM/9L4564rZAsM4MppXgtkCu0wNqxb62QEWIK82IubZAMKJX33W2tkB+sjmBvr62QEWOzL2yx7ZAi3Bjwk6/tkBnrucgRnm2QKUFsQAWbbZALMe97HxetkB+UtQY84O2QBEriZWl67ZA0aslhLout0BZ/zQUXFa3QGGzkVkxabdA2Vresc9lt0CjBlcqZGW3QFXVAv0ET7dAk9e4VxoWt0APqd+Tmg63QKMBzewPGrdANUAcO4get0Af6wdhnzO3QFkiMYBdSLdARj6Cc2Jbt0CghfZQqne3QN/SH76FdLdAKZVqzvCHt0CP/TEpc5i3QNErGaB4oLdA6NKcyPO5t0C2MkVlyry3QCe5B5osx7dAnHv/dTu0t0DM/BT2/6G3QMBAd/A1ubdA3OFrjPKtt0CiZM5Bjqm3QOQKlSf3tbdA39OOLlmst0Ak7j7wdTq3QGkZvc1IDLdARZEJiN4ht0Cxy6FIoUS3QONnBPdWerdA\"},\"shape\":[405],\"dtype\":\"float64\",\"order\":\"little\"}],[\"error\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[405],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1555\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1556\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1551\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"index\"},\"y\":{\"type\":\"field\",\"field\":\"actual\"},\"line_color\":\"#1f77b4\",\"line_width\":2}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1552\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"index\"},\"y\":{\"type\":\"field\",\"field\":\"actual\"},\"line_color\":\"#1f77b4\",\"line_alpha\":0.1,\"line_width\":2}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1553\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"index\"},\"y\":{\"type\":\"field\",\"field\":\"actual\"},\"line_color\":\"#1f77b4\",\"line_alpha\":0.2,\"line_width\":2}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1565\",\"attributes\":{\"data_source\":{\"id\":\"p1509\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1566\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1567\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1562\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"index\"},\"y\":{\"type\":\"field\",\"field\":\"predicted\"},\"line_color\":\"#ff7f0e\",\"line_width\":2}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1563\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"index\"},\"y\":{\"type\":\"field\",\"field\":\"predicted\"},\"line_color\":\"#ff7f0e\",\"line_alpha\":0.1,\"line_width\":2}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1564\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"index\"},\"y\":{\"type\":\"field\",\"field\":\"predicted\"},\"line_color\":\"#ff7f0e\",\"line_alpha\":0.2,\"line_width\":2}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1521\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1534\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1535\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1536\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1537\",\"attributes\":{\"syncable\":false,\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"handles\":{\"type\":\"object\",\"name\":\"BoxInteractionHandles\",\"id\":\"p1543\",\"attributes\":{\"all\":{\"type\":\"object\",\"name\":\"AreaVisuals\",\"id\":\"p1542\",\"attributes\":{\"fill_color\":\"white\",\"hover_fill_color\":\"lightgray\"}}}}}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1544\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1545\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1546\"},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p1547\",\"attributes\":{\"renderers\":\"auto\",\"tooltips\":[[\"Index\",\"@index\"],[\"Actual\",\"@actual{0.000}\"],[\"Predicted\",\"@predicted{0.000}\"],[\"Error\",\"@error{0.000}\"]]}}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1529\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1530\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1531\"},\"axis_label\":\"Value\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1532\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1524\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1525\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1526\"},\"axis_label\":\"Sample Index\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1527\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1528\",\"attributes\":{\"axis\":{\"id\":\"p1524\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1533\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1529\"}}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p1557\",\"attributes\":{\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1558\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Actual\"},\"renderers\":[{\"id\":\"p1554\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1568\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Predicted\"},\"renderers\":[{\"id\":\"p1565\"}]}}]}}]}}]}}]}};\n","  const render_items = [{\"docid\":\"2289ab4c-e224-4869-b026-23790794533f\",\"roots\":{\"p1569\":\"fb89f40e-ebde-4251-b6fb-cd323e5093cd\"},\"root_ids\":[\"p1569\"]}];\n","  void root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n","  }\n","  if (root.Bokeh !== undefined) {\n","    embed_document(root);\n","  } else {\n","    let attempts = 0;\n","    const timer = setInterval(function(root) {\n","      if (root.Bokeh !== undefined) {\n","        clearInterval(timer);\n","        embed_document(root);\n","      } else {\n","        attempts++;\n","        if (attempts > 100) {\n","          clearInterval(timer);\n","          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n","        }\n","      }\n","    }, 10, root)\n","  }\n","})(window);"],"application/vnd.bokehjs_exec.v0+json":""},"metadata":{"application/vnd.bokehjs_exec.v0+json":{"id":"p1569"}}},{"output_type":"stream","name":"stderr","text":["<ipython-input-23-a283884d2bac>:149: UserWarning: save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\n","  save(fig, filename=pred_plot_path)\n","<ipython-input-23-a283884d2bac>:149: UserWarning: save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\n","  save(fig, filename=pred_plot_path)\n"]},{"output_type":"display_data","data":{"text/html":["\n","  <div id=\"db611c50-b2c3-4419-b1fa-dfad648fdc51\" data-root-id=\"p1579\" style=\"display: contents;\"></div>\n"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["(function(root) {\n","  function embed_document(root) {\n","  const docs_json = {\"2fc51122-d273-46fd-ba8b-bde2da331207\":{\"version\":\"3.6.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1579\",\"attributes\":{\"height\":400,\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1580\"},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1581\"},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1589\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LogScale\",\"id\":\"p1590\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1582\",\"attributes\":{\"text\":\"Model Loss Over Time (Log Scale)\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1621\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1576\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1577\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1578\"},\"data\":{\"type\":\"map\",\"entries\":[[\"epoch\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500]],[\"train_loss\",[0.8632264137268066,0.8145182728767395,0.7695915699005127,0.7274594902992249,0.6882437467575073,0.6518190503120422,0.6177734732627869,0.5857711434364319,0.5556043982505798,0.5271331071853638,0.5002490282058716,0.47485828399658203,0.4508745074272156,0.4282152056694031,0.4067988395690918,0.38654449582099915,0.3673711121082306,0.34919998049736023,0.3319563865661621,0.31557103991508484,0.29998213052749634,0.2851349413394928,0.2709823250770569,0.25748366117477417,0.24460379779338837,0.2323119193315506,0.2205808311700821,0.20938578248023987,0.1987040787935257,0.18851454555988312,0.17879720032215118,0.16953296959400177,0.16070348024368286,0.15229107439517975,0.1442786157131195,0.13664956390857697,0.12938787043094635,0.12247798591852188,0.11590491980314255,0.10965418070554733,0.10371175408363342,0.09806407243013382,0.09269816428422928,0.0876014307141304,0.08276181668043137,0.078167624771595,0.07380766421556473,0.06967116892337799,0.06574781984090805,0.062027644366025925,0.058501165360212326,0.05515923723578453,0.051993150264024734,0.048994582146406174,0.046155598014593124,0.0434686541557312,0.04092659056186676,0.03852260857820511,0.0362502858042717,0.034103553742170334,0.032076675444841385,0.03016425482928753,0.028361152857542038,0.026662511751055717,0.025063658133149147,0.023560089990496635,0.022147396579384804,0.020821239799261093,0.019577309489250183,0.01841129921376705,0.017318930476903915,0.01629597134888172,0.015338278375566006,0.014441844075918198,0.013602848164737225,0.012817710638046265,0.012083157896995544,0.011396271176636219,0.0107544781640172,0.010155370458960533,0.009596562944352627,0.009075669571757317,0.008590391837060452,0.008138760924339294,0.007720230612903833,0.007347340229898691,0.007040194235742092,0.0067686596885323524,0.006502172909677029,0.006242496892809868,0.00599463889375329,0.005758180283010006,0.005532132461667061,0.005316463764756918,0.00511116161942482,0.004914781078696251,0.0047234101220965385,0.0045351870357990265,0.004349352791905403,0.004155102651566267,0.003963508177548647,0.003779491875320673,0.003592320252209902,0.0034196360502392054,0.003240373916924,0.0030765060801059008,0.0029150228947401047,0.002761996816843748,0.002617130521684885,0.002480716910213232,0.002354630036279559,0.0022377807181328535,0.0021280949003994465,0.0020264138001948595,0.0019303432200103998,0.0018476935802027583,0.0018019928829744458,0.0017991442000493407,0.0018028519116342068,0.0016424284549430013,0.001575994654558599,0.0015030239010229707,0.0014653786784037948,0.0015408926410600543,0.0015962193720042706,0.0013774741673842072,0.0013171390164643526,0.001273909816518426,0.0012605709489434958,0.0012490672525018454,0.001291553839109838,0.001246006228029728,0.0012206709943711758,0.0011787713738158345,0.0011734486324712634,0.0011446706485003233,0.0011281173210591078,0.0011387290433049202,0.0011500664986670017,0.0010913006262853742,0.0010828198865056038,0.0010752120288088918,0.0010665395529940724,0.0010600691894069314,0.001052499283105135,0.001057127956300974,0.001059533329680562,0.0010586024727672338,0.0010552695021033287,0.0010518472408875823,0.0010425786022096872,0.0010380391031503677,0.0010367266368120909,0.0010349445510655642,0.0010328912176191807,0.0010298341512680054,0.0010286661563441157,0.001027527847327292,0.0010264611337333918,0.0010253327200189233,0.0010239839321002364,0.001023453427478671,0.0010228431783616543,0.0010222727432847023,0.0010216942755505443,0.0010210424661636353,0.0010207660961896181,0.0010204745922237635,0.001020178198814392,0.0010198847157880664,0.001019567484036088,0.0010194240603595972,0.0010192790068686008,0.0010191319743171334,0.0010189843596890569,0.0010188267333433032,0.0010187539737671614,0.001018680864945054,0.001018607523292303,0.0010185339488089085,0.0010184558341279626,0.001018419163301587,0.0010183823760598898,0.0010183460544794798,0.0010183092672377825,0.0010182705009356141,0.0010182517580688,0.0010182334808632731,0.0010182150872424245,0.0010181966936215758,0.001018177135847509,0.0010181681718677282,0.001018158975057304,0.0010181497782468796,0.001018140697851777,0.0010181310353800654,0.001018126611597836,0.0010181221878156066,0.001018117880448699,0.0010181135730817914,0.0010181090328842402,0.0010181068209931254,0.001018104376271367,0.0010181018151342869,0.001018099719658494,0.0010180971585214138,0.0010180952958762646,0.0010180933168157935,0.0010180913377553225,0.0010180893586948514,0.0010180873796343803,0.0010180854005739093,0.0010180834215134382,0.001018081558868289,0.0010180794633924961,0.001018077484332025,0.0010180756216868758,0.001018073526211083,0.0010180716635659337,0.0010180695680901408,0.001018067472614348,0.0010180656099691987,0.0010180636309087276,0.0010180616518482566,0.0010180595563724637,0.0010180576937273145,0.0010180557146668434,0.0010180537356063724,0.0010180516401305795,0.0010180496610701084,0.0010180476820096374,0.0010180455865338445,0.0010180436074733734,0.0010180417448282242,0.0010180396493524313,0.0010180375538766384,0.0010180355748161674,0.0010180337121710181,0.0010180316166952252,0.0010180295212194324,0.0010180275421589613,0.001018025679513812,0.0010180235840380192,0.00101802172139287,0.001018019625917077,0.001018017646856606,0.001018015667796135,0.0010180136887356639,0.0010180117096751928,0.0010180096141994,0.001018007518723607,0.001018005539663136,0.001018003560602665,0.0010180018143728375,0.0010179997188970447,0.0010179976234212518,0.0010179955279454589,0.0010179935488849878,0.0010179915698245168,0.0010179895907640457,0.0010179876117035747,0.0010179856326431036,0.0010179836535826325,0.0010179816745221615,0.0010179795790463686,0.0010179774835705757,0.0010179755045101047,0.0010179735254496336,0.0010179715463891625,0.0010179695673286915,0.0010179674718528986,0.0010179654927924275,0.0010179635137319565,0.0010179615346714854,0.0010179595556110144,0.0010179574601352215,0.0010179554810747504,0.0010179535020142794,0.0010179515229538083,0.0010179495438933372,0.001017947681248188,0.0010179453529417515,0.0010179433738812804,0.0010179415112361312,0.0010179392993450165,0.0010179374366998672,0.0010179352248087525,0.0010179333621636033,0.0010179313831031322,0.0010179292876273394,0.0010179273085668683,0.001017925445921719,0.0010179232340306044,0.0010179211385548115,0.0010179191594943404,0.0010179171804338694,0.0010179153177887201,0.0010179132223129272,0.001017911359667778,0.0010179092641919851,0.001017907285131514,0.0010179051896557212,0.001017903327010572,0.001017901231534779,0.0010178991360589862,0.0010178970405831933,0.001017895177938044,0.0010178930824622512,0.0010178911034017801,0.001017889124341309,0.0010178870288655162,0.0010178850498050451,0.0010178829543292522,0.001017881091684103,0.0010178789962083101,0.001017877017147839,0.0010178749216720462,0.0010178729426115751,0.0010178707307204604,0.0010178687516599894,0.0010178667725995183,0.0010178646771237254,0.0010178628144785762,0.0010178607190027833,0.0010178586235269904,0.001017856877297163,0.0010178545489907265,0.0010178526863455772,0.0010178504744544625,0.0010178484953939915,0.0010178463999181986,0.0010178443044424057,0.0010178423253819346,0.00101784011349082,0.0010178381344303489,0.0010178361553698778,0.001017834059894085,0.001017831964418292,0.0010178298689424992,0.0010178277734667063,0.0010178256779909134,0.0010178235825151205,0.0010178216034546494,0.0010178195079788566,0.0010178175289183855,0.0010178153170272708,0.001017813221551478,0.0010178112424910069,0.0010178090305998921,0.0010178069351240993,0.0010178047232329845,0.0010178027441725135,0.0010178006486967206,0.0010177986696362495,0.0010177964577451348,0.0010177944786846638,0.001017792266793549,0.0010177900549024343,0.0010177879594266415,0.0010177860967814922,0.0010177838848903775,0.0010177816729992628,0.00101777957752347,0.0010177775984629989,0.001017775502987206,0.001017773407511413,0.0010177713120356202,0.0010177691001445055,0.0010177671210840344,0.0010177649091929197,0.0010177630465477705,0.0010177609510719776,0.001017758739180863,0.00101775664370507,0.0010177547810599208,0.001017752569168806,0.0010177504736930132,0.0010177483782172203,0.0010177462827414274,0.0010177443036809564,0.0010177422082051635,0.0010177399963140488,0.0010177380172535777,0.0010177359217777848,0.0010177339427173138,0.0010177318472415209,0.0010177296353504062,0.001017727772705257,0.0010177254443988204,0.0010177234653383493,0.0010177213698625565,0.0010177193908020854,0.0010177172953262925,0.0010177150834351778,0.0010177131043747067,0.0010177107760682702,0.0010177087970077991,0.0010177067015320063,0.0010177047224715352,0.0010177026269957423,0.001017700764350593,0.0010176985524594784,0.0010176964569836855,0.0010176943615078926,0.0010176923824474216,0.0010176904033869505,0.0010176883079111576,0.0010176862124353647,0.0010176841169595718,0.0010176821378991008,0.0010176801588386297,0.001017677946947515,0.0010176758514717221,0.001017673872411251,0.00101767189335078,0.001017669914290309,0.001017667818814516,0.0010176657233387232,0.0010176637442782521,0.0010176616488024592,0.0010176595533266664,0.0010176575742661953,0.0010176554787904024,0.0010176534997299314,0.0010176512878388166,0.0010176491923630238,0.0010176472133025527,0.001017645001411438,0.0010176431387662888,0.0010176410432904959,0.001017638947814703,0.00101763685233891,0.0010176349896937609,0.001017632894217968,0.001017630915157497,0.001017628819681704,0.001017626840621233,0.0010176246287301183,0.0010176225332543254,0.0010176204377785325,0.0010176183423027396,0.0010176162468269467,0.0010176143841817975,0.0010176122887060046,0.0010176101932302117,0.0010176080977544188,0.0010176061186939478,0.001017604023218155,0.0010176020441576838,0.001017599948681891,0.00101759796962142,0.001017595874145627,0.001017593895085156,0.0010175916831940413,0.001017589820548892,0.0010175876086577773,0.00101758586242795,0.0010175836505368352,0.0010175816714763641,0.0010175795760005713,0.0010175774805247784,0.0010175755014643073,0.001017573638819158,0.001017571659758687,0.001017569680698216,0.0010175674688071012,0.0010175657225772738,0.0010175635106861591,0.0010175614152103662,0.001017559552565217,0.0010175574570894241,0.001017555478028953,0.001017553498968482,0.0010175514034926891,0.001017549424432218,0.0010175475617870688,0.0010175455827265978,0.001017543487250805,0.0010175416246056557,0.0010175395291298628,0.0010175375500693917,0.0010175356874242425,0.0010175337083637714,0.0010175316128879786,0.0010175296338275075,0.0010175276547670364,0.0010175257921218872,0.0010175238130614161,0.001017521950416267,0.001017519854940474,0.0010175179922953248,0.0010175161296501756,0.0010175143834203482,0.0010175124043598771,0.0010175103088840842,0.0010175085626542568,0.0010175067000091076,0.0010175047209486365,0.0010175028583034873,0.0010175008792430162]],[\"val_loss\",[0.6852158308029175,0.6477044820785522,0.6124206781387329,0.5794327855110168,0.5487848520278931,0.5201812982559204,0.4933142066001892,0.46798914670944214,0.4440806806087494,0.42149507999420166,0.4001532793045044,0.37998372316360474,0.3609185218811035,0.342892050743103,0.3258386552333832,0.30969372391700745,0.29439327120780945,0.2798762023448944,0.2660853862762451,0.2529691159725189,0.24048124253749847,0.2285815328359604,0.2172350287437439,0.20641155540943146,0.1960844099521637,0.1862301230430603,0.17682743072509766,0.16785681247711182,0.15930010378360748,0.1511402428150177,0.14336103200912476,0.1359468400478363,0.12888264656066895,0.12215397506952286,0.11574676632881165,0.10964743793010712,0.10384286195039749,0.09832029789686203,0.09306752681732178,0.08807269483804703,0.08332443237304688,0.07881171256303787,0.07452404499053955,0.07045124471187592,0.06658359616994858,0.0629117414355278,0.05942671000957489,0.05611993372440338,0.05298318713903427,0.050008613616228104,0.04718871787190437,0.04451633617281914,0.04198462888598442,0.03958712890744209,0.0373176671564579,0.03517039865255356,0.033139776438474655,0.03122054412961006,0.02940773218870163,0.027696609497070312,0.02608266845345497,0.024561604484915733,0.023129276931285858,0.021781647577881813,0.020514775067567825,0.019324781373143196,0.018207808956503868,0.017160044983029366,0.016177698969841003,0.01525705587118864,0.014394471421837807,0.01358642429113388,0.012829557061195374,0.012120693922042847,0.011456895619630814,0.010835488326847553,0.010254129767417908,0.009710817597806454,0.009203825145959854,0.008731509558856487,0.008292176760733128,0.007883991114795208,0.0075049614533782005,0.00715287821367383,0.0068253022618591785,0.006526586599647999,0.006269572768360376,0.006028828676789999,0.005795042030513287,0.005572357680648565,0.005361819174140692,0.005162359680980444,0.004973515868186951,0.004795038141310215,0.004625625442713499,0.0044596558436751366,0.004293334670364857,0.004135449416935444,0.0039748987182974815,0.003812355687841773,0.003658715635538101,0.0035015102475881577,0.0033571752719581127,0.003203789936378598,0.0030669441912323236,0.0029284232296049595,0.0027976117562502623,0.002672754693776369,0.002554855542257428,0.0024492675438523293,0.002352938987314701,0.002257181564345956,0.0021669601555913687,0.002082407707348466,0.0020091221667826176,0.001988077536225319,0.0020081191323697567,0.0018980959430336952,0.0018050511134788394,0.0017724059289321303,0.0017010431038215756,0.0017297780141234398,0.0019387630745768547,0.0016874492866918445,0.0015948867658153176,0.0015820235712453723,0.0015562120825052261,0.001737149665132165,0.0018293889006599784,0.001992227742448449,0.001694803941063583,0.0014904040144756436,0.0014370388817042112,0.001370092504657805,0.0013412125408649445,0.0013458908069878817,0.001383114024065435,0.0013405079953372478,0.0013014785945415497,0.0013077338226139545,0.0012927049538120627,0.001285779639147222,0.001282715704292059,0.0012725219130516052,0.0012663311790674925,0.0012560870964080095,0.001250348868779838,0.0012482202146202326,0.0012462652521207929,0.0012444582534953952,0.0012440282152965665,0.0012433312367647886,0.0012409563641995192,0.0012395348167046905,0.0012380502885207534,0.001238100347109139,0.0012365179136395454,0.0012359218671917915,0.0012347204610705376,0.0012338976375758648,0.0012337216176092625,0.001233058632351458,0.0012325847055763006,0.0012320909881964326,0.0012315723579376936,0.0012314418563619256,0.0012312073959037662,0.0012309282319620252,0.0012306658318266273,0.0012304125120863318,0.0012303197290748358,0.0012302122777327895,0.0012300880625844002,0.0012299570953473449,0.0012298261281102896,0.0012297703651711345,0.0012297137873247266,0.0012296547647565603,0.0012295929482206702,0.0012295297347009182,0.0012294994667172432,0.00122946931514889,0.001229439047165215,0.0012294079642742872,0.001229376532137394,0.001229361747391522,0.0012293461477383971,0.0012293310137465596,0.0012293155305087566,0.0012292995816096663,0.0012292918981984258,0.0012292840983718634,0.0012292766477912664,0.0012292686151340604,0.001229260815307498,0.0012292570900171995,0.0012292532483115792,0.0012292496394366026,0.0012292459141463041,0.0012292418396100402,0.00122923927847296,0.0012292368337512016,0.001229234505444765,0.0012292322935536504,0.001229229848831892,0.0012292292667552829,0.0012292281026020646,0.0012292270548641682,0.00122922589071095,0.0012292246101424098,0.0012292235624045134,0.0012292222818359733,0.0012292213505133986,0.0012292203027755022,0.001229219138622284,0.0012292179744690657,0.0012292169267311692,0.0012292158789932728,0.0012292144820094109,0.0012292134342715144,0.0012292126193642616,0.0012292113387957215,0.0012292099418118596,0.0012292088940739632,0.001229207729920745,0.0012292065657675266,0.0012292052851989865,0.0012292041210457683,0.0012292028404772282,0.00122920167632401,0.0012292005121707916,0.0012291992316022515,0.0012291980674490333,0.001229196903295815,0.001229195622727275,0.0012291943421587348,0.001229192828759551,0.0012291914317756891,0.0012291900347918272,0.001229188754223287,0.001229187473654747,0.0012291863095015287,0.0012291850289329886,0.0012291836319491267,0.0012291820021346211,0.0012291806051507592,0.0012291793245822191,0.001229178044013679,0.001229176647029817,0.0012291752500459552,0.0012291738530620933,0.0012291724560782313,0.0012291711755096912,0.0012291698949411511,0.0012291681487113237,0.0012291668681427836,0.0012291654711589217,0.0012291640741750598,0.0012291626771911979,0.0012291610473766923,0.001229159883223474,0.0012291581369936466,0.0012291570892557502,0.0012291554594412446,0.0012291540624573827,0.0012291523162275553,0.0012291509192436934,0.0012291495222598314,0.001229147776030004,0.0012291460298001766,0.0012291448656469584,0.0012291433522477746,0.0012291420716792345,0.001229140325449407,0.0012291386956349015,0.0012291374150663614,0.0012291359016671777,0.0012291345046833158,0.0012291328748688102,0.0012291311286389828,0.0012291297316551208,0.001229128334671259,0.0012291267048567533,0.0012291250750422478,0.0012291234452277422,0.0012291220482438803,0.0012291206512600183,0.001229118905030191,0.001229117508046329,0.0012291157618165016,0.0012291142484173179,0.0012291127350181341,0.0012291111052036285,0.001229109475389123,0.001229108078405261,0.00122910609934479,0.0012291049351915717,0.0012291031889617443,0.001229101442731917,0.0012290999293327332,0.0012290982995182276,0.0012290969025343657,0.0012290949234738946,0.001229093293659389,0.001229092013090849,0.001229089917615056,0.0012290884042158723,0.0012290870072320104,0.0012290850281715393,0.001229083281941712,0.00122908188495785,0.0012290803715586662,0.0012290788581594825,0.001229077111929655,0.001229075132869184,0.001229073852300644,0.0012290721060708165,0.0012290707090869546,0.0012290687300264835,0.001229067100211978,0.0012290658196434379,0.0012290638405829668,0.0012290620943531394,0.0012290606973692775,0.00122905895113945,0.0012290573213249445,0.0012290553422644734,0.0012290538288652897,0.0012290521990507841,0.0012290501035749912,0.0012290481245145202,0.001229046261869371,0.0012290446320548654,0.001229042885825038,0.0012290406739339232,0.0012290390441194177,0.0012290370650589466,0.0012290349695831537,0.0012290332233533263,0.001229031477123499,0.0012290298473089933,0.0012290278682485223,0.0012290256563574076,0.001229024026542902,0.001229021931067109,0.001229019952006638,0.0012290180893614888,0.001229015993885696,0.001229013898409903,0.0012290122685953975,0.0012290101731196046,0.0012290080776438117,0.001229005865752697,0.0012290041195228696,0.0012290021404623985,0.001229000510647893,0.0012289981823414564,0.0012289963196963072,0.0012289943406358361,0.0012289921287447214,0.0012289901496842504,0.0012289882870391011,0.00122898630797863,0.001228984328918159,0.0012289824662730098,0.001228980254381895,0.0012289786245673895,0.0012289766455069184,0.001228974899277091,0.0012289730366319418,0.0012289710575714707,0.0012289690785109997,0.001228967448696494,0.0012289657024666667,0.0012289637234061956,0.0012289616279304028,0.0012289597652852535,0.0012289580190554261,0.0012289561564102769,0.0012289546430110931,0.001228952081874013,0.001228950684890151,0.00122894870582968,0.0012289471924304962,0.0012289452133700252,0.001228943350724876,0.001228941255249083,0.0012289397418498993,0.0012289376463741064,0.001228935900144279,0.0012289342703297734,0.0012289324076846242,0.0012289304286241531,0.0012289289152249694,0.001228927168995142,0.001228925073519349,0.0012289232108741999,0.0012289216974750161,0.0012289200676605105,0.0012289178557693958,0.0012289161095395684,0.0012289144797250628,0.0012289127334952354,0.0012289111036807299,0.0012289092410355806,0.001228907611221075,0.0012289062142372131,0.001228904235176742,0.0012289027217775583,0.001228900859132409,0.0012288992293179035,0.0012288977159187198,0.0012288960861042142,0.0012288943398743868,0.0012288927100598812,0.0012288909638300538,0.0012288892176002264,0.0012288878206163645,0.001228886190801859,0.0012288846774026752,0.0012288830475881696,0.0012288809521123767,0.001228879438713193,0.0012288776924833655,0.0012288764119148254,0.001228874665684998,0.0012288729194551706,0.0012288711732253432,0.0012288696598261595,0.0012288682628422976,0.0012288662837818265,0.0012288647703826427,0.0012288630241528153,0.0012288615107536316,0.001228859880939126,0.001228857901878655,0.0012288563884794712,0.0012288548750802875,0.00122885312885046,0.0012288513826206326,0.0012288496363908052,0.0012288475409150124,0.0012288462603464723,0.001228844397701323,0.0012288425350561738,0.0012288409052416682,0.0012288391590118408,0.0012288371799513698,0.001228835666552186,0.0012288341531530023,0.0012288326397538185,0.001228831009939313,0.0012288294965401292,0.0012288275174796581,0.0012288260040804744,0.0012288244906812906,0.0012288230936974287,0.0012288214638829231,0.0012288198340684175,0.001228818204253912,0.0012288164580240846,0.001228814828209579,0.0012288130819797516,0.001228811452165246,0.0012288102880120277,0.0012288084253668785,0.0012288070283830166,0.0012288052821531892,0.00122880341950804,0.0012288019061088562,0.0012288002762943506,0.001228798646479845,0.0012287969002500176,0.0012287955032661557,0.0012287938734516501,0.0012287921272218227,0.001228790613822639,0.0012287888675928116,0.0012287874706089497,0.001228785840794444,0.0012287843273952603,0.0012287826975807548,0.001228781184181571,0.0012287794379517436,0.0012287782737985253,0.0012287762947380543,0.0012287748977541924,0.0012287735007703304,0.0012287718709558249,0.001228770357556641,0.0012287687277421355,0.0012287672143429518,0.001228765700943768,0.0012287641875445843,0.0012287627905607224,0.0012287615099921823,0.0012287598801776767,0.0012287584831938148,0.0012287572026252747,0.001228755689226091]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1622\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1623\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1618\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"epoch\"},\"y\":{\"type\":\"field\",\"field\":\"train_loss\"},\"line_color\":\"#1f77b4\",\"line_width\":2}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1619\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"epoch\"},\"y\":{\"type\":\"field\",\"field\":\"train_loss\"},\"line_color\":\"#1f77b4\",\"line_alpha\":0.1,\"line_width\":2}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1620\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"epoch\"},\"y\":{\"type\":\"field\",\"field\":\"train_loss\"},\"line_color\":\"#1f77b4\",\"line_alpha\":0.2,\"line_width\":2}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1632\",\"attributes\":{\"data_source\":{\"id\":\"p1576\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1633\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1634\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1629\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"epoch\"},\"y\":{\"type\":\"field\",\"field\":\"val_loss\"},\"line_color\":\"#ff7f0e\",\"line_width\":2}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1630\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"epoch\"},\"y\":{\"type\":\"field\",\"field\":\"val_loss\"},\"line_color\":\"#ff7f0e\",\"line_alpha\":0.1,\"line_width\":2}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1631\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"epoch\"},\"y\":{\"type\":\"field\",\"field\":\"val_loss\"},\"line_color\":\"#ff7f0e\",\"line_alpha\":0.2,\"line_width\":2}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1588\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1601\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1602\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1603\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1604\",\"attributes\":{\"syncable\":false,\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"handles\":{\"type\":\"object\",\"name\":\"BoxInteractionHandles\",\"id\":\"p1610\",\"attributes\":{\"all\":{\"type\":\"object\",\"name\":\"AreaVisuals\",\"id\":\"p1609\",\"attributes\":{\"fill_color\":\"white\",\"hover_fill_color\":\"lightgray\"}}}}}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1611\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1612\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1613\"},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p1614\",\"attributes\":{\"renderers\":\"auto\",\"tooltips\":[[\"Epoch\",\"@epoch\"],[\"Training Loss\",\"@train_loss{0.000}\"],[\"Validation Loss\",\"@val_loss{0.000}\"]]}}]}},\"left\":[{\"type\":\"object\",\"name\":\"LogAxis\",\"id\":\"p1596\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"LogTicker\",\"id\":\"p1597\",\"attributes\":{\"num_minor_ticks\":10,\"mantissas\":[1,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"LogTickFormatter\",\"id\":\"p1598\"},\"axis_label\":\"Loss (log)\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1599\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1591\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1592\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1593\"},\"axis_label\":\"Epoch\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1594\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1595\",\"attributes\":{\"axis\":{\"id\":\"p1591\"},\"grid_line_alpha\":0.3}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1600\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1596\"},\"grid_line_alpha\":0.3}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p1624\",\"attributes\":{\"click_policy\":\"hide\",\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1625\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Training Loss\"},\"renderers\":[{\"id\":\"p1621\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1635\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Validation Loss\"},\"renderers\":[{\"id\":\"p1632\"}]}}]}}]}}]}};\n","  const render_items = [{\"docid\":\"2fc51122-d273-46fd-ba8b-bde2da331207\",\"roots\":{\"p1579\":\"db611c50-b2c3-4419-b1fa-dfad648fdc51\"},\"root_ids\":[\"p1579\"]}];\n","  void root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n","  }\n","  if (root.Bokeh !== undefined) {\n","    embed_document(root);\n","  } else {\n","    let attempts = 0;\n","    const timer = setInterval(function(root) {\n","      if (root.Bokeh !== undefined) {\n","        clearInterval(timer);\n","        embed_document(root);\n","      } else {\n","        attempts++;\n","        if (attempts > 100) {\n","          clearInterval(timer);\n","          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n","        }\n","      }\n","    }, 10, root)\n","  }\n","})(window);"],"application/vnd.bokehjs_exec.v0+json":""},"metadata":{"application/vnd.bokehjs_exec.v0+json":{"id":"p1579"}}},{"output_type":"stream","name":"stderr","text":["<ipython-input-23-a283884d2bac>:154: UserWarning: save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\n","  save(training_plot, filename=history_plot_path)\n","<ipython-input-23-a283884d2bac>:154: UserWarning: save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\n","  save(training_plot, filename=history_plot_path)\n"]},{"output_type":"stream","name":"stdout","text":["[✓] Run 1/6 complete — GRU_0_10ab968352434ed8987c023d1a5ba9ae\n","🏃 View run GRU_0_10ab968352434ed8987c023d1a5ba9ae at: https://dagshub.com/bojte.csongor/stock_market_prediction_thesis.mlflow/#/experiments/2/runs/10ab968352434ed8987c023d1a5ba9ae\n","🧪 View experiment at: https://dagshub.com/bojte.csongor/stock_market_prediction_thesis.mlflow/#/experiments/2\n","🏃 View run GRU_1_b7eeb6a61d1844c89fe5da6297c6975d at: https://dagshub.com/bojte.csongor/stock_market_prediction_thesis.mlflow/#/experiments/2/runs/b7eeb6a61d1844c89fe5da6297c6975d\n","🧪 View experiment at: https://dagshub.com/bojte.csongor/stock_market_prediction_thesis.mlflow/#/experiments/2\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-16fdd4b70185>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.002\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m run_experiment_group(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GRU\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnum_runs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-a283884d2bac>\u001b[0m in \u001b[0;36mrun_experiment_group\u001b[0;34m(model_type, units, optimizer_config, learning_rate, loss, activation, experiment_name, batch_size, epochs, sequence_length, X_train_data, y_train_data, X_val_data, y_val_data, X_test_data, y_test_data, scaler, feature_cols, norm_type, create_model_fn, use_layer_norm, use_regularization, dropout, save_dir, custom, log_scaled, train_data, val_data, extra_name, num_runs)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"experiment_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             log_run_metadata(\n\u001b[0m\u001b[1;32m     72\u001b[0m                 params={\n\u001b[1;32m     73\u001b[0m                     \u001b[0;34m\"normalization_method\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-efcd71c3be2c>\u001b[0m in \u001b[0;36mlog_run_metadata\u001b[0;34m(params, tags)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlog_run_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/tracking/fluent.py\u001b[0m in \u001b[0;36mlog_param\u001b[0;34m(key, value, synchronous)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0mrun_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_or_start_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0msynchronous\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynchronous\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msynchronous\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mMLFLOW_ENABLE_ASYNC_LOGGING\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mMlflowClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/tracking/client.py\u001b[0m in \u001b[0;36mlog_param\u001b[0;34m(self, run_id, key, value, synchronous)\u001b[0m\n\u001b[1;32m   2038\u001b[0m         )\n\u001b[1;32m   2039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msynchronous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tracking_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/tracking/_tracking_service/client.py\u001b[0m in \u001b[0;36mlog_param\u001b[0;34m(self, run_id, key, value, synchronous)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msynchronous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/store/tracking/rest_store.py\u001b[0m in \u001b[0;36mlog_param\u001b[0;34m(self, run_id, param)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mLogParam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_uuid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         )\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogParam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_experiment_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/store/tracking/rest_store.py\u001b[0m in \u001b[0;36m_call_endpoint\u001b[0;34m(self, api, json_body, endpoint)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_METHOD_TO_INFO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mresponse_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_host_creds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     def search_experiments(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/utils/rest_utils.py\u001b[0m in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0mcall_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"json\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverify_rest_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/utils/rest_utils.py\u001b[0m in \u001b[0;36mhttp_request\u001b[0;34m(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, respect_retry_after_header, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         return _get_http_response_with_retries(\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/utils/request_utils.py\u001b[0m in \u001b[0;36m_get_http_response_with_retries\u001b[0;34m(method, url, max_retries, backoff_factor, backoff_jitter, retry_codes, raise_on_status, allow_redirects, respect_retry_after_header, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mallow_redirects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_redirects\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_redirects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["run_id = \"GRU_0_10ab968352434ed8987c023d1a5ba9ae\"\n","loaded_model = load_model(f\"{CHECKPOINTS_PATH}/GRU/{run_id}.keras\")\n","\n","\n","y_test_real, y_pred_real = evaluate_and_log_metrics(\n","                loaded_model, \"custom_log_split_first\", X_test_log_custom, y_test_log_custom,\n","                custom_log_scaler, model_name=\"Final GRU\", custom=True, log_scaled=True,\n","                last_index=last_index_log, first_value=first_value_log, last_value=last_value_log, train_data=train_log_data_custom, val_data=val_log_data_custom\n","            )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HL-yHjPRr_8L","executionInfo":{"status":"ok","timestamp":1745602967482,"user_tz":-180,"elapsed":2601,"user":{"displayName":"Bőjte Csongor","userId":"17903094301082678762"}},"outputId":"088fa51f-5f02-4ccb-f242-e64f22838b9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","\n","Model Performance Metrics:\n","--------------------------------------------------\n","MAPE: 0.6607%\n","RMSE: 43.18498075\n","MSE: 1864.94256241\n","MAE: 33.07525848\n","MPD (Maximum Percentage Deviation): 4.0411%\n","\n","Point of Maximum Deviation (Index 304):\n","--------------------------------------------------\n","True Value: 5186.330078\n","Predicted Value: 5395.914673\n","Absolute Difference: 209.584595\n","Percentage Deviation: 4.04%\n"]}]},{"cell_type":"code","source":["def generate_description(\n","    model_type: str,\n","    layers: int,\n","    units: list[int],\n","    activation: str,\n","    norm: bool,\n","    reg: bool,\n","    dropout: float,\n","    seq_len: int,\n","    loss: str,\n","    optimizer_name: str,\n","    extra: str = \"\"\n",") -> str:\n","    desc = f\"{model_type}_L{layers}_U{'-'.join(map(str, units))}_{activation}\"\n","    if norm:\n","        desc += \"_norm\"\n","    if reg:\n","        desc += \"_reg\"\n","    if dropout > 0:\n","        desc += f\"_drop{dropout}\"\n","    desc += f\"_seq{seq_len}_{loss}_{optimizer_name}\"\n","    if extra:\n","        desc += f\"_{extra}\"\n","    return desc"],"metadata":{"id":"panUvpjDiwrx"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"eRmoRCeczAqj"},"outputs":[],"source":["def calculate_mpd(y_true, y_pred):\n","    # Convert inputs to numpy arrays if they aren't already\n","    y_true = np.array(y_true).flatten()\n","    y_pred = np.array(y_pred).flatten()\n","\n","    # Calculate percentage deviations\n","    epsilon = 1e-7  # Avoid division by zero\n","    percentage_deviations = np.abs((y_true - y_pred) / (y_true + epsilon)) * 100\n","\n","    # Find maximum deviation and its index\n","    max_deviation = np.max(percentage_deviations)\n","    max_deviation_idx = np.argmax(percentage_deviations)\n","\n","    return {\n","        'mpd': max_deviation,\n","        'index': max_deviation_idx,\n","        'true_value': y_true[max_deviation_idx],\n","        'pred_value': y_pred[max_deviation_idx],\n","        'all_deviations': percentage_deviations\n","    }"]},{"cell_type":"code","source":["def evaluate_predictions(model_name, y_true, y_pred, n_samples=None, should_print=False):\n","    # Flatten arrays if needed\n","    y_pred = y_pred.copy().flatten()\n","    y_true = y_true.copy().flatten()\n","\n","    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n","    rmse = root_mean_squared_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","\n","    # Calculate MPD\n","    mpd_results = calculate_mpd(y_true, y_pred)\n","    mpd = mpd_results['mpd']\n","    mpd_index = mpd_results['index']\n","    true_value_at_mpd = mpd_results['true_value']\n","    pred_value_at_mpd = mpd_results['pred_value']\n","    percentage_deviations = mpd_results['all_deviations']\n","\n","    if should_print:\n","        # Print metrics\n","        print(\"\\nModel Performance Metrics:\")\n","        print(\"-\" * 50)\n","        print(f\"MAPE: {mape:.4f}%\")\n","        print(f\"RMSE: {rmse:.8f}\")\n","        print(f\"MSE: {mse:.8f}\")\n","        print(f\"MAE: {mae:.8f}\")\n","        print(f\"MPD (Maximum Percentage Deviation): {mpd:.4f}%\")\n","\n","         # Print point of maximum deviation\n","        print(f\"\\nPoint of Maximum Deviation (Index {mpd_index}):\")\n","        print(\"-\" * 50)\n","        print(f\"True Value: {y_true[mpd_index]:.6f}\")\n","        print(f\"Predicted Value: {y_pred[mpd_index]:.6f}\")\n","        print(f\"Absolute Difference: {abs(y_true[mpd_index] - y_pred[mpd_index]):.6f}\")\n","        print(f\"Percentage Deviation: {percentage_deviations[mpd_index]:.2f}%\")\n","\n","        # Print sample predictions\n","        if n_samples:\n","          print(f\"\\nFirst {n_samples} Predictions:\")\n","          print(\"-\" * 50)\n","          print(\"Index    True Value    Predicted    Difference    % Deviation\")\n","          print(\"-\" * 65)\n","          for i in range(min(n_samples, len(y_true))):\n","              diff = y_true[i] - y_pred[i]\n","              dev = percentage_deviations[i]\n","              print(f\"{i:<8d} {y_true[i]:11.6f}  {y_pred[i]:11.6f}  {diff:11.6f}  {dev:11.2f}%\")\n","\n","    # save_model_metrics(model_name, {\n","    #     'mape': mape,\n","    #     'mse': mse,\n","    #     'rmse': rmse,\n","    #     'mae': mae,\n","    #     'mpd': mpd,\n","    #     'mpd_index': mpd_index,\n","    # }, f\"{METRICS_PATH}/model_metrics.csv\")\n","\n","    return {\n","        'mape': mape,\n","        'mse': mse,\n","        'rmse': rmse,\n","        'mae': mae,\n","        'mpd': mpd,\n","        'mpd_index': mpd_index,\n","        'percentage_deviations': percentage_deviations}"],"metadata":{"id":"0GYQi-gvMcLh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ej-zVtWlg0zH"},"outputs":[],"source":["def plot_training_history(history):\n","    output_notebook()\n","\n","    # Create data sources\n","    epochs = list(range(1, len(history.history['loss']) + 1))\n","\n","    # Ensure values are positive for log scale (add small epsilon if needed)\n","    epsilon = 1e-10\n","    train_loss = [max(val, epsilon) for val in history.history['loss']]\n","    val_loss = [max(val, epsilon) for val in history.history['val_loss']]\n","\n","    source_loss = ColumnDataSource(data={\n","        'epoch': epochs,\n","        'train_loss': train_loss,\n","        'val_loss': val_loss\n","    })\n","\n","    p1 = figure(title='Model Loss Over Time (Log Scale)',\n","               x_axis_label='Epoch',\n","               y_axis_label='Loss (log)',\n","               width=600, height=400,\n","               y_axis_type=\"log\")\n","\n","    # Add hover tool\n","    hover_loss = HoverTool(tooltips=[\n","        ('Epoch', '@epoch'),\n","        ('Training Loss', '@train_loss{0.000}'),\n","        ('Validation Loss', '@val_loss{0.000}')\n","    ])\n","    p1.add_tools(hover_loss)\n","\n","    # Plot loss lines\n","    l1 = p1.line('epoch', 'train_loss', line_color=Category10[3][0],\n","                 line_width=2, source=source_loss, legend_label='Training Loss')\n","    l2 = p1.line('epoch', 'val_loss', line_color=Category10[3][1],\n","                 line_width=2, source=source_loss, legend_label='Validation Loss')\n","\n","    # Configure legends\n","    for p in [p1]:\n","        p.legend.click_policy = \"hide\"\n","        p.legend.location = \"top_right\"\n","        p.grid.grid_line_alpha = 0.3\n","\n","    # Show plots\n","    show(p1)\n","    return p1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mzsv14br1DgC"},"outputs":[],"source":["def plot_predictions_bokeh(y_test, y_pred, n_samples=None):\n","    output_notebook()\n","\n","    if n_samples is None:\n","        n_samples = len(y_test)\n","    else:\n","        n_samples = min(n_samples, len(y_test))\n","\n","    # Prepare data\n","    x_range = list(range(n_samples))\n","    source = ColumnDataSource(data={\n","        'index': x_range,\n","        'actual': y_test[:n_samples],\n","        'predicted': y_pred[:n_samples],\n","        'error': y_test[:n_samples] - y_pred[:n_samples]\n","    })\n","\n","    # Create time series plot\n","    p1 = figure(title='Actual vs Predicted Values',\n","                x_axis_label='Sample Index',\n","                y_axis_label='Value',\n","                width=800, height=400)\n","\n","    # Add hover tool\n","    hover = HoverTool(tooltips=[\n","        ('Index', '@index'),\n","        ('Actual', '@actual{0.000}'),\n","        ('Predicted', '@predicted{0.000}'),\n","        ('Error', '@error{0.000}')\n","    ])\n","    p1.add_tools(hover)\n","\n","    # Plot lines\n","    l1 = p1.line('index', 'actual', line_color=Category10[3][0],\n","                 line_width=2, source=source, legend_label='Actual')\n","    l2 = p1.line('index', 'predicted', line_color=Category10[3][1],\n","                 line_width=2, source=source, legend_label='Predicted')\n","\n","    # Show plots\n","    show(row(p1))\n","\n","    return p1;"]}]}